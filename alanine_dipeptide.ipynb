{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1\n",
        "!pip install --quiet torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install --quiet torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
        "    -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "!pip install --quiet openmm mdtraj parmed tqdm pandas numpy\n",
        "!pip install pymbar statsmodels\n",
        "\n",
        "import platform, sys, subprocess\n",
        "import importlib.metadata as metadata\n",
        "\n",
        "pkgs = [\n",
        "    \"torch\", \"torchvision\", \"torchaudio\",\n",
        "    \"torch-scatter\", \"torch-sparse\", \"torch-cluster\", \"torch-spline-conv\", \"torch-geometric\",\n",
        "    \"openmm\", \"mdtraj\", \"parmed\", \"tqdm\", \"pandas\", \"numpy\", \"pymbar\", \"statsmodels\"\n",
        "]\n",
        "\n",
        "print(\"=== Python & OS Info ===\")\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(f\"Platform: {platform.platform()}\")\n",
        "\n",
        "print(\"\\n=== Hardware Info ===\")\n",
        "!nvidia-smi\n",
        "\n",
        "print(\"\\n=== Installed Package Versions ===\")\n",
        "for pkg in pkgs:\n",
        "    try:\n",
        "        ver = metadata.version(pkg)\n",
        "    except metadata.PackageNotFoundError:\n",
        "        ver = \"Not installed\"\n",
        "    print(f\"{pkg}: {ver}\")\n",
        "\n",
        "import torch\n",
        "print(\"\\n=== PyTorch CUDA Info ===\")\n",
        "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version (PyTorch): {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "GmzRu1ARapVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "out_root = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "os.makedirs(out_root, exist_ok=True)\n",
        "print(\"Output →\", out_root)"
      ],
      "metadata": {
        "id": "ExAijoOrajWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3\n",
        "import json, numpy as np, mdtraj as md\n",
        "from openmm.app import PDBFile, Modeller, ForceField, Simulation, DCDReporter, StateDataReporter, NoCutoff, HBonds\n",
        "from openmm import LangevinIntegrator, unit\n",
        "\n",
        "n_reps         = 3\n",
        "frames_per_rep = 8000\n",
        "report_every   = 50\n",
        "timestep_fs    = 2.0\n",
        "\n",
        "meta = {\n",
        "    'solvent':      'implicit (OBC2)',\n",
        "    'forcefield':   ['amber99sbildn.xml','amber99_obc.xml'],\n",
        "    'integrator':   'Langevin',\n",
        "    'temperature':  300,\n",
        "    'friction_ps^-1': 1.0,\n",
        "    'timestep_fs':  timestep_fs,\n",
        "    'frames_per_rep': frames_per_rep,\n",
        "    'dt_ps':        timestep_fs * report_every / 1000,\n",
        "    'n_replicas':   n_reps\n",
        "}\n",
        "with open(os.path.join(out_root,'metadata.json'),'w') as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print(\"Saved metadata.json\")"
      ],
      "metadata": {
        "id": "IU8qJT6sabvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4\n",
        "!wget -q https://raw.githubusercontent.com/choderalab/YankTools/master/testsystems/data/alanine-dipeptide-gbsa/alanine-dipeptide.pdb \\\n",
        "    -O alanine_dipeptide.pdb\n",
        "\n",
        "pdb      = PDBFile('alanine_dipeptide.pdb')\n",
        "ff_impl  = ForceField('amber99sbildn.xml', 'amber99_obc.xml')\n",
        "modeller = Modeller(pdb.topology, pdb.positions)\n",
        "\n",
        "system = ff_impl.createSystem(\n",
        "    modeller.topology,\n",
        "    nonbondedMethod=NoCutoff,\n",
        "    constraints=HBonds\n",
        ")\n",
        "integrator = LangevinIntegrator(\n",
        "    300 * unit.kelvin,\n",
        "    1.0 / unit.picosecond,\n",
        "    timestep_fs * unit.femtoseconds\n",
        ")\n",
        "print(\"System + integrator ready\")"
      ],
      "metadata": {
        "id": "7jHnHhcgJ4nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5\n",
        "import numpy as np\n",
        "from tqdm.auto import trange\n",
        "from openmm import unit\n",
        "\n",
        "t_gen_start = time.time()\n",
        "\n",
        "for rep in range(1, n_reps+1):\n",
        "    print(f\"\\n=== Replica {rep}/{n_reps} ===\")\n",
        "    integrator = LangevinIntegrator(\n",
        "        300*unit.kelvin,\n",
        "        1.0/unit.picosecond,\n",
        "        timestep_fs*unit.femtoseconds\n",
        "    )\n",
        "    sim = Simulation(modeller.topology, system, integrator)\n",
        "    sim.context.setPositions(modeller.positions)\n",
        "    sim.minimizeEnergy()\n",
        "    sim.context.setVelocitiesToTemperature(300*unit.kelvin)\n",
        "\n",
        "    rep_dir = os.path.join(out_root, f'rep_{rep:02d}')\n",
        "    os.makedirs(rep_dir, exist_ok=True)\n",
        "    dcd_path = os.path.join(rep_dir, 'traj.dcd')\n",
        "\n",
        "    sim.reporters.append(DCDReporter(dcd_path, report_every))\n",
        "\n",
        "    forces_list, energies_list = [], []\n",
        "\n",
        "    total_steps = frames_per_rep * report_every\n",
        "    for step in trange(total_steps, desc=f\"Replica {rep}\", unit=\"step\"):\n",
        "        sim.step(1)\n",
        "        if step % report_every == 0:\n",
        "            state = sim.context.getState(getForces=True, getEnergy=True)\n",
        "            U = state.getPotentialEnergy().value_in_unit(unit.kilojoule_per_mole)\n",
        "            energies_list.append(U)\n",
        "            f_atoms = state.getForces(asNumpy=True)\\\n",
        "                            .value_in_unit(unit.kilojoule_per_mole/unit.nanometer)\n",
        "            forces_list.append(f_atoms)\n",
        "\n",
        "    np.save(os.path.join(rep_dir, 'forces.npy'),   np.stack(forces_list))\n",
        "    np.save(os.path.join(rep_dir, 'energies.npy'), np.array(energies_list))\n",
        "    print(f\"Replica {rep} done: saved forces.npy({len(forces_list)}) and energies.npy({len(energies_list)})\")\n",
        "\n",
        "t_gen = time.time() - t_gen_start\n",
        "print(f\"Data generation took {t_gen/3600:.2f} hours.\")"
      ],
      "metadata": {
        "id": "Dd05twaWaV72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 6\n",
        "import os, glob\n",
        "\n",
        "root       = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "rep_dirs   = sorted(glob.glob(os.path.join(root, 'rep_*/')))\n",
        "heavy_only_pdb  = os.path.join(root, 'heavy_only.pdb')\n",
        "processed  = os.path.join(root, 'processed')\n",
        "os.makedirs(processed, exist_ok=True)\n",
        "\n",
        "print(\"Found replicas:\", rep_dirs)\n",
        "print(\"Heavy PDB  =\", heavy_only_pdb)\n",
        "print(\"Processed dir:\", processed)"
      ],
      "metadata": {
        "id": "0s_qHtAvaL0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7\n",
        "import shutil\n",
        "\n",
        "full_src = 'alanine_dipeptide.pdb'\n",
        "full_pdb = os.path.join(root, 'full.pdb')\n",
        "\n",
        "if not os.path.exists(full_pdb):\n",
        "    shutil.copy(full_src, full_pdb)\n",
        "    print(\"Copied full PDB to\", full_pdb)\n",
        "else:\n",
        "    print(\"Found existing full PDB:\", full_pdb)"
      ],
      "metadata": {
        "id": "9BxwqHdgaCe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8\n",
        "import numpy as np, mdtraj as md\n",
        "\n",
        "heavy_top = md.load(heavy_only_pdb).topology\n",
        "\n",
        "def project_dihedral_forces(positions, atom_forces,\n",
        "                             phi_idx, psi_idx, omega_idx,\n",
        "                             delta=1e-6):\n",
        "    \"\"\"\n",
        "    Map atomic forces → feature‐space forces for φ,ψ,ω.\n",
        "    positions   : (N_atoms,3) numpy array in nm\n",
        "    atom_forces : (N_atoms,3) numpy array in kJ/mol/nm\n",
        "    phi_idx,psi_idx,omega_idx : lists of 4 atom indices\n",
        "    returns     : (6,) numpy array [dU/dsinφ,dU/dcosφ, …]\n",
        "    \"\"\"\n",
        "    traj0 = md.Trajectory(positions[np.newaxis,:,:], heavy_top)\n",
        "\n",
        "    angles = [\n",
        "        md.compute_dihedrals(traj0, [phi_idx])[0,0],\n",
        "        md.compute_dihedrals(traj0, [psi_idx])[0,0],\n",
        "        md.compute_dihedrals(traj0, [omega_idx])[0,0]\n",
        "    ]\n",
        "    idxs = [phi_idx, psi_idx, omega_idx]\n",
        "\n",
        "    torques = []\n",
        "    for angle0, atom_idx in zip(angles, idxs):\n",
        "        grads = np.zeros_like(positions)\n",
        "\n",
        "        for i in atom_idx:\n",
        "            for ax in range(3):\n",
        "                pos_f = positions.copy(); pos_f[i,ax] += delta\n",
        "                th_f  = md.compute_dihedrals(md.Trajectory(pos_f[np.newaxis,:,:],\n",
        "                                  heavy_top), [atom_idx])[0,0]\n",
        "                pos_b = positions.copy(); pos_b[i,ax] -= delta\n",
        "                th_b  = md.compute_dihedrals(md.Trajectory(pos_b[np.newaxis,:,:],\n",
        "                                  heavy_top), [atom_idx])[0,0]\n",
        "                grads[i,ax] = (th_f - th_b)/(2*delta)\n",
        "\n",
        "        torque = -np.sum(atom_forces * grads)\n",
        "        torques.append(torque)\n",
        "\n",
        "    feats = []\n",
        "    for torque, th in zip(torques, angles):\n",
        "        s, c = np.sin(th), np.cos(th)\n",
        "        feats += [torque * c, -torque * s]\n",
        "\n",
        "    return np.array(feats)"
      ],
      "metadata": {
        "id": "jAJ0yyk74_u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9\n",
        "import mdtraj as md\n",
        "\n",
        "topology = os.path.join(root, 'full.pdb')\n",
        "\n",
        "for rep in rep_dirs:\n",
        "    dcd_in  = os.path.join(rep, 'traj.dcd')\n",
        "    xtc_out = os.path.join(rep, 'heavy_only.xtc')\n",
        "    if os.path.exists(xtc_out):\n",
        "        print(f\"Already have {xtc_out}\")\n",
        "        continue\n",
        "\n",
        "    traj = md.load(dcd_in, top=topology)\n",
        "    keep = [a.index for a in traj.topology.atoms\n",
        "            if a.residue.name in ('ACE','ALA','NME')\n",
        "            and a.element.symbol != 'H']\n",
        "    heavy = traj.atom_slice(keep)\n",
        "    heavy = heavy.superpose(heavy, frame=0)\n",
        "    heavy.save_xtc(xtc_out)\n",
        "    print(f\"Created {xtc_out}\")\n",
        "\n",
        "print(\"All heavy-only XTCs ready.\")"
      ],
      "metadata": {
        "id": "nk3OPCSeZ8b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10\n",
        "import numpy as np, mdtraj as md\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "topology = full_pdb\n",
        "\n",
        "ref = md.load(topology)\n",
        "top = ref.topology\n",
        "phi_idx   = [ top.select('resid 0 and name C')[0],\n",
        "              top.select('resid 1 and name N')[0],\n",
        "              top.select('resid 1 and name CA')[0],\n",
        "              top.select('resid 1 and name C')[0] ]\n",
        "psi_idx   = [ top.select('resid 1 and name N')[0],\n",
        "              top.select('resid 1 and name CA')[0],\n",
        "              top.select('resid 1 and name C')[0],\n",
        "              top.select('resid 2 and name N')[0] ]\n",
        "omega_idx = [ top.select('resid 1 and name CA')[0],\n",
        "              top.select('resid 1 and name C')[0],\n",
        "              top.select('resid 2 and name N')[0],\n",
        "              top.select('resid 2 and name C')[0] ]\n",
        "\n",
        "for rep in rep_dirs:\n",
        "    dcd_in = os.path.join(rep, 'traj.dcd')\n",
        "    out_np = os.path.join(rep, 'internal_full.npy')\n",
        "\n",
        "    traj = md.load(dcd_in, top=topology)\n",
        "\n",
        "    phi   = md.compute_dihedrals(traj, [phi_idx])[:,0]\n",
        "    psi   = md.compute_dihedrals(traj, [psi_idx])[:,0]\n",
        "    omega = md.compute_dihedrals(traj, [omega_idx])[:,0]\n",
        "\n",
        "    feats = np.vstack([\n",
        "        np.sin(phi), np.cos(phi),\n",
        "        np.sin(psi), np.cos(psi),\n",
        "        np.sin(omega), np.cos(omega)\n",
        "    ]).T\n",
        "\n",
        "    np.save(out_np, feats)\n",
        "    print(f\"Saved {os.path.basename(out_np)} → {feats.shape[0]} frames × 6 dims\")"
      ],
      "metadata": {
        "id": "1r6GjlNIZ2cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11\n",
        "import numpy as np\n",
        "\n",
        "all_feats = []\n",
        "for rep in rep_dirs:\n",
        "    data = np.load(os.path.join(rep, 'internal_full.npy'))\n",
        "    all_feats.append(data)\n",
        "\n",
        "stacked = np.vstack(all_feats)\n",
        "mu  = stacked.mean(axis=0)\n",
        "std = stacked.std(axis=0)\n",
        "\n",
        "np.save(os.path.join(processed, 'mu.npy'),  mu)\n",
        "np.save(os.path.join(processed, 'std.npy'), std)\n",
        "print(f\"Saved mu/std ({mu.shape}) to {processed}\")"
      ],
      "metadata": {
        "id": "bScgamqyZwYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12\n",
        "import os, numpy as np, torch\n",
        "\n",
        "t_projection_start = time.time()\n",
        "forces_list, energies_list = [], []\n",
        "\n",
        "for rep in rep_dirs:\n",
        "    F_atoms = np.load(os.path.join(rep, 'forces.npy'))\n",
        "    E       = np.load(os.path.join(rep, 'energies.npy'))\n",
        "\n",
        "    dcd = os.path.join(rep, 'traj.dcd')\n",
        "    traj = md.load(dcd, top=full_pdb)\n",
        "\n",
        "    for i in range(len(E)):\n",
        "        energies_list.append(E[i])\n",
        "        featF = project_dihedral_forces(\n",
        "            positions=traj.xyz[i],\n",
        "            atom_forces=F_atoms[i],\n",
        "            phi_idx=phi_idx,\n",
        "            psi_idx=psi_idx,\n",
        "            omega_idx=omega_idx\n",
        "        )\n",
        "        forces_list.append(featF)\n",
        "\n",
        "forces_arr   = torch.tensor(np.stack(forces_list),   dtype=torch.float32)\n",
        "energies_arr = torch.tensor(np.array(energies_list), dtype=torch.float32)\n",
        "\n",
        "os.makedirs(processed, exist_ok=True)\n",
        "torch.save(forces_arr,   os.path.join(processed, 'forces.pt'))\n",
        "torch.save(energies_arr, os.path.join(processed, 'energies.pt'))\n",
        "print(\"Saved forces.pt\", forces_arr.shape,\n",
        "      \"and energies.pt\", energies_arr.shape)\n",
        "t_proj = time.time() - t_projection_start\n",
        "print(f\"Force projection took {t_proj/3600:.2f} hours.\")"
      ],
      "metadata": {
        "id": "17ZhIb6aZqbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13\n",
        "import os, glob, numpy as np, torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "raw_dir    = root\n",
        "proc_dir   = processed\n",
        "\n",
        "\n",
        "F_all = torch.load(os.path.join(proc_dir, 'forces.pt'))\n",
        "U_all = torch.load(os.path.join(proc_dir, 'energies.pt'))\n",
        "\n",
        "feat_files = sorted(glob.glob(os.path.join(raw_dir, 'rep_*', 'internal_full.npy')))\n",
        "\n",
        "mu  = np.load(os.path.join(proc_dir, 'mu.npy'))\n",
        "std = np.load(os.path.join(proc_dir, 'std.npy'))\n",
        "\n",
        "edge_index = torch.tensor(\n",
        "    [[i, j] for i in range(3) for j in range(3) if i != j],\n",
        "    dtype=torch.long\n",
        ").t()\n",
        "\n",
        "data_list = []\n",
        "idx = 0\n",
        "for fpath in feat_files:\n",
        "    feats = np.load(fpath)[:frames_per_rep]\n",
        "    print(f\"→ {os.path.basename(os.path.dirname(fpath))}: {feats.shape[0]} frames\")\n",
        "    for frame in feats:\n",
        "        norm = (frame - mu) / std\n",
        "        x = torch.tensor(\n",
        "            [[norm[2*i], norm[2*i+1]] for i in range(3)],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        y_force  = F_all[idx]\n",
        "        y_energy = U_all[idx]\n",
        "\n",
        "        data = Data(\n",
        "            x=x,\n",
        "            edge_index=edge_index,\n",
        "            y_force=y_force,\n",
        "            y_energy=y_energy\n",
        "        )\n",
        "        data_list.append(data)\n",
        "        idx += 1\n",
        "\n",
        "print(\"Built dataset of\", len(data_list), \"graphs\")"
      ],
      "metadata": {
        "id": "WORmmqUkZjal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14\n",
        "import random\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "shuffled   = data_list.copy()\n",
        "random.shuffle(shuffled)\n",
        "split      = int(0.9 * len(shuffled))\n",
        "train_list = shuffled[:split]\n",
        "val_list   = shuffled[split:]\n",
        "\n",
        "batch_size    = 16\n",
        "train_loader  = DataLoader(train_list, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "val_loader    = DataLoader(val_list,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"Train graphs: {len(train_list)}, Val graphs: {len(val_list)}\")"
      ],
      "metadata": {
        "id": "NgAyL2zuZYsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import TransformerConv, global_mean_pool\n",
        "import math\n",
        "\n",
        "def sinusoidal_time_embeddings(t, dim):\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(-math.log(1e4) * torch.arange(half, device=t.device) / (half - 1))\n",
        "    args  = t[:, None].float() * freqs[None]\n",
        "    emb   = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
        "    return F.pad(emb, (0,1)) if dim % 2 else emb\n",
        "\n",
        "class GraphDiffusionTransformer(nn.Module):\n",
        "    def __init__(self, node_dim, time_dim, hidden_dim, layers, heads, dropout, timesteps):\n",
        "        super().__init__()\n",
        "        self.timesteps = timesteps\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(time_dim, hidden_dim), nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.x_proj = nn.Linear(node_dim, hidden_dim)\n",
        "        self.convs  = nn.ModuleList([\n",
        "            TransformerConv(hidden_dim, hidden_dim, heads=heads, concat=False, dropout=dropout, beta=True)\n",
        "            for _ in range(layers)\n",
        "        ])\n",
        "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_dim) for _ in range(layers)])\n",
        "        self.out_noise  = nn.Linear(hidden_dim, node_dim)\n",
        "        self.out_force  = nn.Linear(hidden_dim, node_dim)\n",
        "        self.out_energy = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def _forward(self, x, edge_index, batch, t_node):\n",
        "        \"\"\"\n",
        "        x:       (total_nodes, node_dim)\n",
        "        edge_index: graph connectivity\n",
        "        batch:   (total_nodes,) mapping nodes → graph ids\n",
        "        t_node:  (total_nodes,) noise‐level per node\n",
        "        \"\"\"\n",
        "        h = self.x_proj(x) + self.time_mlp(sinusoidal_time_embeddings(t_node, self.time_mlp[0].in_features))\n",
        "        for conv, norm in zip(self.convs, self.norms):\n",
        "            h2 = conv(h, edge_index)\n",
        "            h  = norm(h + h2)\n",
        "\n",
        "        noise = self.out_noise(h)\n",
        "        force = self.out_force(h)\n",
        "\n",
        "        energy_nodes = self.out_energy(h)\n",
        "        energy = global_mean_pool(energy_nodes, batch).view(-1)\n",
        "        return noise, force, energy\n",
        "\n",
        "class GaussianDiffusion(nn.Module):\n",
        "    def __init__(self, betas):\n",
        "        super().__init__()\n",
        "        alphas = 1 - betas\n",
        "        a_cum  = torch.cumprod(alphas, dim=0)\n",
        "        self.register_buffer('sqrt_a_cum',   torch.sqrt(a_cum))\n",
        "        self.register_buffer('sqrt_1ma_cum', torch.sqrt(1 - a_cum))\n",
        "\n",
        "    def q_sample(self, x, t_node, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x)\n",
        "        a = self.sqrt_a_cum[t_node].view(-1,1)\n",
        "        m = self.sqrt_1ma_cum[t_node].view(-1,1)\n",
        "        return a * x + m * noise\n",
        "\n",
        "    def p_losses(self, model, x_start, edge_index, batch, t):\n",
        "        \"\"\"\n",
        "        x_start:   (total_nodes, node_dim)\n",
        "        edge_index, batch: from Data.batch\n",
        "        t:         (batch_size,) random timesteps per graph\n",
        "        \"\"\"\n",
        "        noise   = torch.randn_like(x_start)\n",
        "        t_node  = t[batch]\n",
        "        x_noisy = self.q_sample(x_start, t_node, noise)\n",
        "        noise_pred, force_pred, energy_pred = model._forward(x_noisy, edge_index, batch, t_node)\n",
        "\n",
        "        L_noise  = F.mse_loss(noise_pred, noise)\n",
        "        L_force  = self.λ_f * F.mse_loss(force_pred, self.F_MM[batch])\n",
        "        L_energy = self.λ_E * F.mse_loss(energy_pred, self.U_MM[batch.unique()])\n",
        "        return L_noise, L_force, L_energy"
      ],
      "metadata": {
        "id": "h3B80hrMlyxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16\n",
        "from torch.optim import Adam\n",
        "\n",
        "timesteps  = 1000\n",
        "beta_start = 1e-4\n",
        "beta_end   = 0.02\n",
        "time_dim   = 128\n",
        "hidden_dim = 128\n",
        "layers     = 6\n",
        "heads      = 4\n",
        "dropout    = 0.1\n",
        "lr         = 3e-4\n",
        "epochs     = 50\n",
        "save_every = 50\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = GraphDiffusionTransformer(\n",
        "    node_dim=train_list[0].x.size(1),\n",
        "    time_dim=time_dim,\n",
        "    hidden_dim=hidden_dim,\n",
        "    layers=layers,\n",
        "    heads=heads,\n",
        "    dropout=dropout,\n",
        "    timesteps=timesteps\n",
        ").to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "XpGFA9kEZSFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17\n",
        "T = 1000\n",
        "beta_min, beta_max = 1e-4, 2e-2\n",
        "betas  = torch.linspace(beta_min, beta_max, T, device=device)\n",
        "alphas = 1.0 - betas\n",
        "a_bar  = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "diffusion = GaussianDiffusion(betas).to(device)"
      ],
      "metadata": {
        "id": "1Gq7dOffFkof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "t_train_start = time.time()\n",
        "\n",
        "train_noise_losses = []\n",
        "train_force_losses = []\n",
        "train_energy_losses = []\n",
        "train_total_losses = []\n",
        "valid_noise_losses = []\n",
        "valid_force_losses = []\n",
        "valid_energy_losses = []\n",
        "valid_total_losses = []\n",
        "\n",
        "model = GraphDiffusionTransformer(\n",
        "    node_dim=2, time_dim=time_dim, hidden_dim=hidden_dim,\n",
        "    layers=layers, heads=heads, dropout=dropout, timesteps=timesteps\n",
        ").to(device)\n",
        "diffusion = GaussianDiffusion(betas.to(device)).to(device)\n",
        "diffusion.λ_f = 1.0\n",
        "diffusion.λ_E = 0.1\n",
        "\n",
        "raw_forces   = torch.load(os.path.join(proc_dir, 'forces.pt')).to(device)\n",
        "raw_energies = torch.load(os.path.join(proc_dir, 'energies.pt')).to(device)\n",
        "\n",
        "forces_nodes = raw_forces.view(-1, 3, 2).reshape(-1, 2)\n",
        "F_mean, F_std = forces_nodes.mean(0, keepdim=True), forces_nodes.std(0, keepdim=True)\n",
        "forces_nodes  = (forces_nodes - F_mean) / F_std\n",
        "\n",
        "U_mean, U_std    = raw_energies.mean(), raw_energies.std()\n",
        "energies_norm    = (raw_energies - U_mean) / U_std\n",
        "\n",
        "diffusion.F_MM = forces_nodes\n",
        "diffusion.U_MM = energies_norm\n",
        "\n",
        "ckpt_dir = os.path.join(out_root, 'checkpoints')\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "print(f\"ckpt_dir = {ckpt_dir}\")\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=lr * 0.1)\n",
        "\n",
        "best_val_loss     = float('inf')\n",
        "epochs_no_improve = 0\n",
        "patience          = 5\n",
        "save_best_path    = os.path.join(ckpt_dir, 'model_best.pt')\n",
        "print(f\"Early stopping patience = {patience} epochs; best model → {save_best_path}\")\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    sum_n = sum_f = sum_e = 0.0\n",
        "    model.train()\n",
        "    for batch in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=False):\n",
        "        batch = batch.to(device)\n",
        "        t     = torch.randint(0, timesteps, (batch.num_graphs,), device=device)\n",
        "        L_n, L_f, L_e = diffusion.p_losses(\n",
        "            model, batch.x, batch.edge_index, batch.batch, t\n",
        "        )\n",
        "        loss = L_n + L_f + L_e\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        sum_n += L_n.item() * batch.num_graphs\n",
        "        sum_f += L_f.item() * batch.num_graphs\n",
        "        sum_e += L_e.item() * batch.num_graphs\n",
        "\n",
        "    avg_n = sum_n / len(train_list)\n",
        "    avg_f = sum_f / len(train_list)\n",
        "    avg_e = sum_e / len(train_list)\n",
        "    train_total = avg_n + avg_f + avg_e\n",
        "    print(f\"Epoch {epoch:3d} — \"\n",
        "          f\"L_noise: {avg_n:.5e}, L_force: {avg_f:.5e}, L_energy: {avg_e:.5e}, \"\n",
        "          f\"total: {train_total:.5e}\")\n",
        "    train_noise_losses.append(avg_n)\n",
        "    train_force_losses.append(avg_f)\n",
        "    train_energy_losses.append(avg_e)\n",
        "    train_total_losses.append(train_total)\n",
        "\n",
        "    model.eval()\n",
        "    val_n = val_f = val_e = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Valid\", leave=False):\n",
        "            batch = batch.to(device)\n",
        "            t     = torch.randint(0, timesteps, (batch.num_graphs,), device=device)\n",
        "            L_n, L_f, L_e = diffusion.p_losses(\n",
        "                model, batch.x, batch.edge_index, batch.batch, t\n",
        "            )\n",
        "            val_n += L_n.item() * batch.num_graphs\n",
        "            val_f += L_f.item() * batch.num_graphs\n",
        "            val_e += L_e.item() * batch.num_graphs\n",
        "\n",
        "    avg_vn = val_n / len(val_list)\n",
        "    avg_vf = val_f / len(val_list)\n",
        "    avg_ve = val_e / len(val_list)\n",
        "    val_total = avg_vn + avg_vf + avg_ve\n",
        "    print(f\" Valid - L_noise: {avg_vn:.5e}, L_force: {avg_vf:.5e}, L_energy: {avg_ve:.5e}, \"\n",
        "          f\"total: {val_total:.5e}\")\n",
        "    valid_noise_losses.append(avg_vn)\n",
        "    valid_force_losses.append(avg_vf)\n",
        "    valid_energy_losses.append(avg_ve)\n",
        "    valid_total_losses.append(val_total)\n",
        "\n",
        "    if val_total < best_val_loss:\n",
        "        best_val_loss     = val_total\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), save_best_path)\n",
        "        print(f\"New best model (epoch {epoch}) saved\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve}/{patience} epochs\")\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}; best_val_loss = {best_val_loss:.5e}\")\n",
        "            break\n",
        "\n",
        "    if epoch % save_every == 0:\n",
        "        ck = os.path.join(ckpt_dir, f'model_epoch{epoch:03d}.pt')\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'model': model.state_dict(),\n",
        "                    'opt': opt.state_dict()}, ck)\n",
        "        print(\"Saved\", ck)\n",
        "\n",
        "model.load_state_dict(torch.load(save_best_path))\n",
        "print(f\"Loaded best model from {save_best_path}\")\n",
        "\n",
        "torch.save(model.state_dict(), os.path.join(ckpt_dir, 'model_final.pt'))\n",
        "\n",
        "print(\"Training complete\")\n",
        "t_train = time.time() - t_train_start\n",
        "print(f\"Training took {t_train/3600:.2f} hours.\")\n",
        "\n",
        "epochs = range(1, len(train_noise_losses) + 1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_noise_losses, label='Train')\n",
        "plt.plot(epochs, valid_noise_losses, label='Valid')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Noise loss')\n",
        "plt.title('Noise Loss vs. Epoch')\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_force_losses, label='Train')\n",
        "plt.plot(epochs, valid_force_losses, label='Valid')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Force loss')\n",
        "plt.title('Force Loss vs. Epoch')\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_energy_losses, label='Train')\n",
        "plt.plot(epochs, valid_energy_losses, label='Valid')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Energy loss')\n",
        "plt.title('Energy Loss vs. Epoch')\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_total_losses, label='Train')\n",
        "plt.plot(epochs, valid_total_losses, label='Valid')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Total loss')\n",
        "plt.title('Total Loss vs. Epoch')\n",
        "plt.legend(); plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "KZRgUIomZLeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 19\n",
        "import os\n",
        "\n",
        "output_dir    = '/content/drive/MyDrive/alanine_dipeptide/output'\n",
        "raw_dir       = '/content/drive/MyDrive/alanine_dipeptide/raw'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(raw_dir, exist_ok=True)\n",
        "\n",
        "processed_dir = output_dir\n",
        "ckpt_dir      = os.path.join(output_dir, 'checkpoints')\n",
        "os.makedirs(ckpt_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "1u_G7oy-dsoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 20\n",
        "import torch\n",
        "from openmm.unit import MOLAR_GAS_CONSTANT_R, kilojoule_per_mole, kelvin\n",
        "from openmm import app\n",
        "\n",
        "device     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model      = model.to(device)\n",
        "edge_index = edge_index.to(device)\n",
        "\n",
        "timesteps = 1000\n",
        "alphas    = 1 - betas\n",
        "a_cumprod = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "T0       = 150\n",
        "sqrt_ab  = a_cumprod[T0].sqrt()\n",
        "sqrt_1mab= (1 - a_cumprod[T0]).sqrt()\n",
        "\n",
        "max_tries = 20\n",
        "kT_q = MOLAR_GAS_CONSTANT_R * 300 * kelvin\n",
        "kT   = kT_q.value_in_unit(kilojoule_per_mole)\n",
        "lam       = 0.15\n",
        "\n",
        "pdb_path = os.path.join(raw_dir, 'full.pdb')\n",
        "\n",
        "pdb_full = PDBFile(pdb_path)\n",
        "\n",
        "heavy_indices = [\n",
        "    atom.index for atom in pdb_full.topology.atoms()\n",
        "    if atom.element.symbol!='H' and atom.residue.name not in ('HOH','WAT')\n",
        "]"
      ],
      "metadata": {
        "id": "X8wu4yWyeIOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 21\n",
        "import sys, os, math, numpy as np, torch, mdtraj as md\n",
        "from openmm.app import (\n",
        "    PDBFile, Modeller, ForceField, NoCutoff, HBonds, Simulation\n",
        ")\n",
        "from openmm import (\n",
        "    CustomTorsionForce, LocalEnergyMinimizer,\n",
        "    LangevinIntegrator, unit\n",
        ")\n",
        "\n",
        "raw_dir      = '/content/drive/MyDrive/alanine_dipeptide/raw'\n",
        "gbsa_ff      = ForceField('amber99_obc.xml', 'amber99sbildn.xml')\n",
        "\n",
        "peptide_residue_names = ['ACE', 'ALA', 'NME']\n",
        "heavy_to_full = [\n",
        "    a.index for r in pdb_full.topology.residues()\n",
        "    if r.name in peptide_residue_names\n",
        "    for a in r.atoms() if a.element.symbol != 'H'\n",
        "]\n",
        "full_np = np.array([v.value_in_unit(unit.nanometer) for v in pdb_full.positions])\n",
        "\n",
        "implicit_modeller = Modeller(pdb_full.topology, pdb_full.positions)\n",
        "implicit_modeller.addHydrogens(gbsa_ff)\n",
        "\n",
        "peptide_heavy_idx_mod = [\n",
        "    a.index for r in implicit_modeller.topology.residues()\n",
        "    if r.name in peptide_residue_names\n",
        "    for a in r.atoms() if a.element.symbol != 'H'\n",
        "]\n",
        "\n",
        "heavy_to_full_mod = peptide_heavy_idx_mod.copy()\n",
        "\n",
        "def reconstruct_frame_with_openmm(phi, psi, omega, implicit_modeller):\n",
        "    \"\"\"\n",
        "    Rebuild the peptide in implicit solvent with stiff φ/ψ/ω restraints.\n",
        "    Returns (coords_nm, phi_atoms, psi_atoms, omega_atoms) or Nones on error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        m = implicit_modeller\n",
        "\n",
        "        system = gbsa_ff.createSystem(\n",
        "            m.topology, nonbondedMethod=NoCutoff, constraints=HBonds\n",
        "        )\n",
        "\n",
        "        ct = CustomTorsionForce(\n",
        "            \"k*min((theta-theta0)^2,(2*pi-abs(theta-theta0))^2)\"\n",
        "        )\n",
        "        ct.addPerTorsionParameter(\"theta0\")\n",
        "        ct.addGlobalParameter(\"pi\", np.pi)\n",
        "        ct.addPerTorsionParameter(\"k\")\n",
        "        k_val = 100.0 * unit.kilojoule_per_mole / unit.radian**2\n",
        "\n",
        "        top = m.topology\n",
        "        C_ACE = next(a.index for r in top.residues() if r.name=='ACE' for a in r.atoms() if a.name=='C')\n",
        "        N_ALA = next(a.index for r in top.residues() if r.name=='ALA' for a in r.atoms() if a.name=='N')\n",
        "        CA_ALA= next(a.index for r in top.residues() if r.name=='ALA' for a in r.atoms() if a.name=='CA')\n",
        "        C_ALA = next(a.index for r in top.residues() if r.name=='ALA' for a in r.atoms() if a.name=='C')\n",
        "        N_NME = next(a.index for r in top.residues() if r.name=='NME' for a in r.atoms() if a.name=='N')\n",
        "        C_NME = next(a.index for r in top.residues() if r.name=='NME' for a in r.atoms() if a.name=='C')\n",
        "\n",
        "        phi_atoms   = [C_ACE, N_ALA, CA_ALA, C_ALA]\n",
        "        psi_atoms   = [N_ALA, CA_ALA, C_ALA, N_NME]\n",
        "        omega_atoms = [CA_ALA, C_ALA, N_NME, C_NME]\n",
        "\n",
        "        ct.addTorsion(*phi_atoms,   [phi,   k_val])\n",
        "        ct.addTorsion(*psi_atoms,   [psi,   k_val])\n",
        "        ct.addTorsion(*omega_atoms, [omega, k_val])\n",
        "        system.addForce(ct)\n",
        "\n",
        "        sim = Simulation(top, system, LangevinIntegrator(300*unit.kelvin,1/unit.picosecond,0.002*unit.picosecond))\n",
        "        sim.context.setPositions(m.positions)\n",
        "        sim.minimizeEnergy(maxIterations=500)\n",
        "\n",
        "        coords = sim.context.getState(getPositions=True)\\\n",
        "                    .getPositions(asNumpy=True).value_in_unit(unit.nanometer)\n",
        "        return coords, phi_atoms, psi_atoms, omega_atoms\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error in reconstruct_frame_with_openmm:\", e)\n",
        "        sys.excepthook(type(e), e, e.__traceback__)\n",
        "        return None, None, None, None\n",
        "\n",
        "def reconstruct_heavy(feat: np.ndarray) -> np.ndarray:\n",
        "    phi, psi, omg = (math.atan2(feat[0], feat[1]),\n",
        "                     math.atan2(feat[2], feat[3]),\n",
        "                     math.atan2(feat[4], feat[5]))\n",
        "    coords, *_ = reconstruct_frame_with_openmm(phi, psi, omg, implicit_modeller)\n",
        "    return coords[peptide_heavy_idx_mod]\n",
        "\n",
        "def energy_from_heavy(heavy_xyz: np.ndarray, tol: float = 10.0) -> float:\n",
        "    \"\"\"\n",
        "    heavy_xyz : (N_heavy,3) nm  — coordinates of the peptide heavy atoms\n",
        "    Returns    : potential energy in kJ/mol\n",
        "    \"\"\"\n",
        "    m = Modeller(implicit_modeller.topology, implicit_modeller.positions)\n",
        "\n",
        "    pos_arr = np.asarray(m.positions.value_in_unit(unit.nanometer))\n",
        "\n",
        "    pos_arr[np.asarray(peptide_heavy_idx_mod), :] = heavy_xyz\n",
        "\n",
        "    m.positions = pos_arr * unit.nanometer\n",
        "\n",
        "    system = gbsa_ff.createSystem(\n",
        "        m.topology, nonbondedMethod=NoCutoff, constraints=HBonds\n",
        "    )\n",
        "    sim = Simulation(\n",
        "        m.topology, system,\n",
        "        LangevinIntegrator(300*unit.kelvin, 1/unit.picosecond, 0.002*unit.picosecond)\n",
        "    )\n",
        "    sim.context.setPositions(m.positions)\n",
        "\n",
        "    return sim.context.getState(getEnergy=True)\\\n",
        "              .getPotentialEnergy()\\\n",
        "              .value_in_unit(unit.kilojoule_per_mole)\n",
        "\n",
        "def compute_openmm_forces(x_feat, delta=1e-3):\n",
        "    \"\"\"\n",
        "    x_feat: torch.Tensor shape (3,2) with [sin,cos] for φ,ψ,ω.\n",
        "    Returns torch.Tensor shape (3,2): ∂U/∂[sin,cos] for each dihedral.\n",
        "    \"\"\"\n",
        "    arr = x_feat.cpu().numpy()\n",
        "    angles = np.arctan2(arr[:,0], arr[:,1])  # [φ,ψ,ω]\n",
        "\n",
        "    grads = []\n",
        "    for i, theta in enumerate(angles):\n",
        "        th_f = theta + delta\n",
        "        th_b = theta - delta\n",
        "\n",
        "        arr_f = angles.copy(); arr_b = angles.copy()\n",
        "        arr_f[i] = th_f; arr_b[i] = th_b\n",
        "\n",
        "        def to_feats(ths):\n",
        "            return np.stack([np.sin(ths), np.cos(ths)], axis=1)\n",
        "\n",
        "        x_f = to_feats(arr_f)\n",
        "        x_b = to_feats(arr_b)\n",
        "\n",
        "        U_f = energy_from_heavy(reconstruct_heavy(x_f.flatten()))\n",
        "        U_b = energy_from_heavy(reconstruct_heavy(x_b.flatten()))\n",
        "\n",
        "        dU_dθ = (U_f - U_b)/(2*delta)\n",
        "\n",
        "        s, c = arr[i]\n",
        "        denom = s*s + c*c\n",
        "        dθ_ds =  c/denom\n",
        "        dθ_dc = -s/denom\n",
        "\n",
        "        grads.append([dU_dθ * dθ_ds, dU_dθ * dθ_dc])\n",
        "\n",
        "    return torch.tensor(grads, device=device, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "8llp7Sww-PIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 22\n",
        "import numpy as np, math\n",
        "import torch\n",
        "\n",
        "α = 0.01\n",
        "\n",
        "def mh_jump(x_in):\n",
        "    \"\"\"\n",
        "    x_in   : torch.Tensor on device, shape (3,2)\n",
        "    returns: (x_prop, mu) for downstream Δlog p\n",
        "    \"\"\"\n",
        "    if not hasattr(mh_jump, \"_proposals\"):\n",
        "        mh_jump._proposals = []\n",
        "        mh_jump._delta_vecs = []\n",
        "    for i in range(max_tries):\n",
        "        print(f\"→   inside mh_jump: T0={T0}, lam={lam}\")\n",
        "\n",
        "        noise = torch.randn_like(x_in)\n",
        "        xT    = sqrt_ab * x_in + sqrt_1mab * noise\n",
        "\n",
        "        t_node    = torch.zeros(x_in.size(0), dtype=torch.long, device=device)\n",
        "        batch_vec = torch.zeros_like(t_node)\n",
        "        eps, _, _ = model._forward(xT, edge_index, batch_vec, t_node)\n",
        "\n",
        "        F_xt   = compute_openmm_forces(xT)\n",
        "        guided = eps - α * F_xt\n",
        "\n",
        "        β_t  = betas[T0]\n",
        "        α_t  = alphas[T0]\n",
        "        ᾱ_t = a_bar[T0]\n",
        "\n",
        "        coef1 = 1.0 / torch.sqrt(α_t)\n",
        "        coef2 = β_t / torch.sqrt(1.0 - ᾱ_t)\n",
        "        mu    = coef1 * (xT - coef2 * guided)\n",
        "\n",
        "        x_prop = (1 - lam) * x_in + lam * mu\n",
        "\n",
        "\n",
        "        mh_jump._proposals.append(x_prop.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "        mh_jump._delta_vecs.append((x_prop - x_in).detach().cpu().numpy())\n",
        "\n",
        "\n",
        "        Δx = (x_prop - x_in).abs().max().item()\n",
        "        print(f\"→   max |Δx| = {Δx:.3e}\")\n",
        "\n",
        "        φ_prop = math.degrees(math.atan2(x_prop[0,0].item(), x_prop[0,1].item()))\n",
        "        φ_old  = math.degrees(math.atan2(x_in[0,0].item(),  x_in[0,1].item()))\n",
        "        print(f\"→   Δφ = {φ_prop - φ_old:.2f}°\")\n",
        "        ψ_prop = math.degrees(math.atan2(x_prop[1,0].item(), x_prop[1,1].item()))\n",
        "        ψ_old  = math.degrees(math.atan2(x_in[1,0].item(),  x_in[1,1].item()))\n",
        "        print(f\"→   Δψ = {ψ_prop - ψ_old:.2f}°\")\n",
        "\n",
        "        return x_prop, mu"
      ],
      "metadata": {
        "id": "DD57sx5fAdE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 23\n",
        "import os, mdtraj as md, math\n",
        "from openmm.app import (\n",
        "    PDBFile, Modeller, ForceField, Simulation,\n",
        "    DCDReporter, StateDataReporter, NoCutoff, HBonds\n",
        ")\n",
        "from openmm import LangevinIntegrator, unit, CustomTorsionForce, LocalEnergyMinimizer\n",
        "from openmm.app import AllBonds\n",
        "import mdtraj.utils.unit\n",
        "mdtraj.utils.unit.openmm_unit = unit\n",
        "\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "pdb_path = os.path.join(raw_dir, 'full.pdb')\n",
        "\n",
        "pdb_full = PDBFile(pdb_path)\n",
        "gbsa_ff   = ForceField('amber99sbildn.xml', 'amber99_obc.xml')\n",
        "modeller  = Modeller(pdb_full.topology, pdb_full.positions)\n",
        "modeller.addHydrogens(gbsa_ff)\n",
        "implicit_modeller = modeller\n",
        "\n",
        "heavy_ref = md.load(os.path.join(raw_dir, 'heavy_only.pdb'))\n",
        "heavy_top = heavy_ref.topology\n",
        "\n",
        "ace_C_idx  = heavy_top.select('resid 0 and name C')[0]\n",
        "ala_N_idx  = heavy_top.select('resid 1 and name N')[0]\n",
        "ala_CA_idx = heavy_top.select('resid 1 and name CA')[0]\n",
        "ala_C_idx  = heavy_top.select('resid 1 and name C')[0]\n",
        "nme_N_idx  = heavy_top.select('resid 2 and name N')[0]\n",
        "nme_C_idx  = heavy_top.select('resid 2 and name C')[0]\n",
        "\n",
        "phi_indices   = [ace_C_idx, ala_N_idx, ala_CA_idx, ala_C_idx]\n",
        "psi_indices   = [ala_N_idx, ala_CA_idx, ala_C_idx, nme_N_idx]\n",
        "omega_indices = [ala_CA_idx, ala_C_idx, nme_N_idx, nme_C_idx]\n",
        "\n",
        "system     = gbsa_ff.createSystem(\n",
        "    implicit_modeller.topology,\n",
        "    nonbondedMethod=NoCutoff,\n",
        "    constraints=HBonds\n",
        ")\n",
        "integrator = LangevinIntegrator(\n",
        "    300*unit.kelvin,\n",
        "    1/unit.picosecond,\n",
        "    0.002*unit.picosecond\n",
        ")\n",
        "\n",
        "tors_force = CustomTorsionForce(\n",
        "    \"0.5*k*min(abs(theta-theta0), 2*pi-abs(theta-theta0))\"\n",
        "    \"*min(abs(theta-theta0), 2*pi-abs(theta-theta0))\"\n",
        ")\n",
        "tors_force.addPerTorsionParameter(\"theta0\")\n",
        "tors_force.addPerTorsionParameter(\"k\")\n",
        "tors_force.addGlobalParameter(\"pi\", math.pi)\n",
        "k_val  = 100.0 * unit.kilojoule_per_mole / unit.radian**2\n",
        "k_zero = 0.0   * unit.kilojoule_per_mole / unit.radian**2\n",
        "\n",
        "\n",
        "phi_id   = tors_force.addTorsion(*phi_indices,   [0.0, k_zero])\n",
        "psi_id   = tors_force.addTorsion(*psi_indices,   [0.0, k_zero])\n",
        "omega_id = tors_force.addTorsion(*omega_indices, [0.0, k_zero])\n",
        "\n",
        "system.addForce(tors_force)\n",
        "\n",
        "simulation = Simulation(\n",
        "    implicit_modeller.topology,\n",
        "    system,\n",
        "    integrator\n",
        ")\n",
        "simulation.context.setPositions(implicit_modeller.positions)\n",
        "simulation.minimizeEnergy()\n",
        "simulation.context.setVelocitiesToTemperature(300*unit.kelvin)\n",
        "\n",
        "simulation.reporters.append(\n",
        "    DCDReporter(os.path.join(output_dir, 'hybrid.dcd'), 50)\n",
        ")\n",
        "simulation.reporters.append(\n",
        "    StateDataReporter(\n",
        "        os.path.join(output_dir, 'hybrid.log'),\n",
        "        5000, step=True, time=True,\n",
        "        potentialEnergy=True, temperature=True\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "s5FU_Bf0BZvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 24\n",
        "import mdtraj as md\n",
        "from openmm.app import PDBFile\n",
        "\n",
        "full_top_omm = simulation.topology\n",
        "\n",
        "heavy_to_full = [\n",
        "    atom.index for atom in full_top_omm.atoms()\n",
        "    if atom.element.symbol != 'H' and atom.residue.name in ('ACE','ALA','NME')\n",
        "]\n",
        "\n",
        "full_top_md   = md.Topology.from_openmm(full_top_omm)\n",
        "heavy_top     = full_top_md.subset(heavy_to_full)\n",
        "\n",
        "print(\"heavy_top atoms :\", heavy_top.n_atoms)\n",
        "\n",
        "implicit_full  = PDBFile(full_pdb)\n",
        "imp_mod_traj   = md.Topology.from_openmm(implicit_full.topology)\n",
        "implicit_top_md = imp_mod_traj\n",
        "\n",
        "ace_C  = heavy_top.select('resname ACE and name C')[0]\n",
        "ala_N  = heavy_top.select('resname ALA and name N')[0]\n",
        "ala_CA = heavy_top.select('resname ALA and name CA')[0]\n",
        "ala_C  = heavy_top.select('resname ALA and name C')[0]\n",
        "nme_N  = heavy_top.select('resname NME and name N')[0]\n",
        "nme_C  = heavy_top.select('resname NME and name C')[0]\n",
        "\n",
        "phi_indices   = [ace_C,  ala_N, ala_CA, ala_C]\n",
        "psi_indices   = [ala_N,  ala_CA, ala_C, nme_N]\n",
        "omega_indices = [ala_CA, ala_C,  nme_N, nme_C]\n",
        "\n",
        "print(\"phi_indices :\", phi_indices)\n",
        "print(\"psi_indices :\", psi_indices)\n",
        "print(\"omega_indices:\", omega_indices)\n",
        "print(\"heavy_top atoms:\", heavy_top.n_atoms)"
      ],
      "metadata": {
        "id": "XuQMT_Q0ZAoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 25\n",
        "import os, math, random, numpy as np, mdtraj as md, torch, time\n",
        "from openmm import unit, LocalEnergyMinimizer\n",
        "\n",
        "t_sample_start = time.time()\n",
        "\n",
        "force_reject = False\n",
        "\n",
        "total_ns        = 80\n",
        "dt_ps           = 0.002\n",
        "total_steps     = int(total_ns*1000.0 / dt_ps)\n",
        "\n",
        "injection_ns    = 2.0\n",
        "steps_per_block = int(injection_ns * 1e3 / dt_ps)\n",
        "cumulative_steps = 0\n",
        "block = 0\n",
        "\n",
        "max_min_steps   = 500\n",
        "bar_pairs       = []\n",
        "accepted_log    = []\n",
        "U_old           = None\n",
        "\n",
        "T0   = 150\n",
        "var  = (1 - a_cumprod[T0]).item()\n",
        "\n",
        "def potential_energy_kj(sim):\n",
        "    return sim.context.getState(getEnergy=True) \\\n",
        "               .getPotentialEnergy().value_in_unit(unit.kilojoule_per_mole)\n",
        "\n",
        "while cumulative_steps < total_steps:\n",
        "    block += 1\n",
        "\n",
        "    simulation.step(steps_per_block)\n",
        "    cumulative_steps += steps_per_block\n",
        "\n",
        "    U_current = potential_energy_kj(simulation)\n",
        "    if U_old is None:\n",
        "        U_old = U_current\n",
        "\n",
        "    state_old = simulation.context.getState(\n",
        "        getPositions=True, getVelocities=True, enforcePeriodicBox=True\n",
        "    )\n",
        "\n",
        "    xyz_full  = simulation.context.getState(getPositions=True)\\\n",
        "                        .getPositions(asNumpy=True).value_in_unit(unit.nanometer)\n",
        "    heavy_xyz = xyz_full[heavy_to_full]\n",
        "    traj0     = md.Trajectory(xyz=heavy_xyz[np.newaxis,:,:], topology=heavy_top)\n",
        "    φ, ψ, ω   = (\n",
        "        md.compute_dihedrals(traj0, [phi_indices])[0,0],\n",
        "        md.compute_dihedrals(traj0, [psi_indices])[0,0],\n",
        "        md.compute_dihedrals(traj0, [omega_indices])[0,0],\n",
        "    )\n",
        "\n",
        "    x_feat = torch.tensor([\n",
        "        [math.sin(φ), math.cos(φ)],\n",
        "        [math.sin(ψ), math.cos(ψ)],\n",
        "        [math.sin(ω), math.cos(ω)],\n",
        "    ], dtype=torch.float32, device=device)\n",
        "\n",
        "    x_prop, mu = mh_jump(x_feat)\n",
        "    bar_pairs.append([U_current, None, 0.0])\n",
        "    accepted_log.append(False)\n",
        "\n",
        "    feat_np = x_prop.detach().cpu().numpy().flatten()\n",
        "    φp, ψp, ωp = (\n",
        "        math.atan2(feat_np[0], feat_np[1]),\n",
        "        math.atan2(feat_np[2], feat_np[3]),\n",
        "        math.atan2(feat_np[4], feat_np[5]),\n",
        "    )\n",
        "    for tors_id, idxs, th in [(phi_id, phi_indices,   φp),\n",
        "                              (psi_id, psi_indices,   ψp),\n",
        "                              (omega_id,omega_indices,ωp)]:\n",
        "        tors_force.setTorsionParameters(tors_id, *idxs, [th, k_val])\n",
        "    tors_force.updateParametersInContext(simulation.context)\n",
        "\n",
        "    print(f\"DEBUG pre-minimize proposal → φ={math.degrees(φp):.2f}°, \"\n",
        "          f\"ψ={math.degrees(ψp):.2f}°, ω={math.degrees(ωp):.2f}°\")\n",
        "\n",
        "    LocalEnergyMinimizer.minimize(\n",
        "        simulation.context,\n",
        "        10*unit.kilojoule_per_mole/unit.nanometer,\n",
        "        maxIterations=max_min_steps\n",
        "    )\n",
        "\n",
        "    state = simulation.context.getState(getPositions=True)\n",
        "    pos   = state.getPositions(asNumpy=True).value_in_unit(unit.nanometer)\n",
        "\n",
        "    traj_min = md.Trajectory(pos[heavy_to_full][np.newaxis,:,:], heavy_top)\n",
        "    phi_act   = md.compute_dihedrals(traj_min, [phi_indices])[0,0]\n",
        "    psi_act   = md.compute_dihedrals(traj_min, [psi_indices])[0,0]\n",
        "    omega_act = md.compute_dihedrals(traj_min, [omega_indices])[0,0]\n",
        "    print(f\"DEBUG post-minimize actual   → φ={math.degrees(phi_act):.2f}°, \"\n",
        "          f\"ψ={math.degrees(psi_act):.2f}°, ω={math.degrees(omega_act):.2f}°\")\n",
        "\n",
        "    U_prop = potential_energy_kj(simulation)\n",
        "\n",
        "    diff_old   =       (x_feat - mu).view(-1).pow(2).sum().item()\n",
        "    diff_new   =       (x_prop - mu).view(-1).pow(2).sum().item()\n",
        "    const_term = -0.5 * x_feat.numel() * math.log(2*math.pi*var)\n",
        "    logp_old   =  const_term - 0.5 * diff_old/var\n",
        "    logp_new   =  const_term - 0.5 * diff_new/var\n",
        "    delta_logp =  logp_new - logp_old\n",
        "    bar_pairs[-1][2] = delta_logp\n",
        "\n",
        "    U_old_prev = U_old\n",
        "\n",
        "    kT      = (unit.MOLAR_GAS_CONSTANT_R * 300 * unit.kelvin)\\\n",
        "                   .value_in_unit(unit.kilojoule_per_mole)\n",
        "    delta   = (U_old - U_prop) / kT\n",
        "    d_clamp = max(min(delta, 50.0), -50.0)\n",
        "    acc_prob= math.exp(d_clamp)\n",
        "    accept  = (delta >= 0.0) or (random.random() < acc_prob)\n",
        "    if force_reject:\n",
        "      accept = False\n",
        "\n",
        "    if accept:\n",
        "        for tors_id, idxs in [(phi_id, phi_indices),\n",
        "                              (psi_id, psi_indices),\n",
        "                              (omega_id,omega_indices)]:\n",
        "            tors_force.setTorsionParameters(tors_id, *idxs, [0.0, k_zero])\n",
        "        tors_force.updateParametersInContext(simulation.context)\n",
        "        accepted_log[-1]          = True\n",
        "        U_old = U_prop\n",
        "    else:\n",
        "        simulation.context.setState(state_old)\n",
        "        for tors_id, idxs in [(phi_id, phi_indices),\n",
        "                              (psi_id, psi_indices),\n",
        "                              (omega_id,omega_indices)]:\n",
        "            tors_force.setTorsionParameters(tors_id, *idxs, [0.0, k_zero])\n",
        "        tors_force.updateParametersInContext(simulation.context)\n",
        "\n",
        "        U_prop                    = potential_energy_kj(simulation)\n",
        "\n",
        "    bar_pairs[-1][0] = U_old_prev\n",
        "    bar_pairs[-1][1] = U_prop\n",
        "\n",
        "    deltaE = U_prop - U_old_prev\n",
        "    total_ns_run = cumulative_steps * dt_ps / 1000.0\n",
        "    print(f\"Block {block:2d} — accept={accepted_log[-1]}  \"\n",
        "          f\"U_old={U_old_prev:.2f}  U_prop={U_prop:.2f}  \"\n",
        "          f\"ΔE={deltaE:+.2f}  acc_prob={acc_prob:.1e}  \"\n",
        "          f\"total_ns={total_ns_run:.3f} ns\")\n",
        "\n",
        "np.save(os.path.join(processed_dir,'bar_log.npy'),   np.array(bar_pairs),   allow_pickle=False)\n",
        "np.save(os.path.join(processed_dir,'accepted.npy'), np.array(accepted_log), allow_pickle=False)\n",
        "np.save(os.path.join(processed_dir, 'hybrid_proposals.npy'),\n",
        "        np.stack(mh_jump._proposals))\n",
        "np.save(os.path.join(processed_dir, 'hybrid_delta_x.npy'),\n",
        "        np.stack(mh_jump._delta_vecs))\n",
        "\n",
        "t_sample = time.time() - t_sample_start\n",
        "print(\"✓ Saved bar_log.npy, accepted.npy, hybrid_proposals.npy, and hybrid_delta_x.npy\")\n",
        "print(f\"Sampling took {t_sample/3600:.2f} hours.\")"
      ],
      "metadata": {
        "id": "__MxzCr3Y3-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Cell (Hybrid)\n",
        "import mdtraj as md\n",
        "import os\n",
        "\n",
        "root       = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "output_dir = os.path.join(root, 'output')\n",
        "\n",
        "dcd_path      = os.path.join(output_dir, 'hybrid.dcd')\n",
        "log_path      = os.path.join(output_dir, 'hybrid.log')\n",
        "topology_path = os.path.join(root,       'full.pdb')\n",
        "\n",
        "print(\"DCD exists?   \", os.path.exists(dcd_path), dcd_path)\n",
        "print(\"LOG exists?   \", os.path.exists(log_path), log_path)\n",
        "print(\"PDB exists?   \", os.path.exists(topology_path), topology_path)\n",
        "\n",
        "traj = md.load_dcd(dcd_path, top=topology_path)\n",
        "print(f\"Loaded hybrid trajectory: {traj.n_frames} frames × {traj.n_atoms} atoms\")\n",
        "\n",
        "print(\"\\nFirst 10 lines of hybrid.log:\")\n",
        "with open(log_path, 'r') as f:\n",
        "    for _ in range(10):\n",
        "        print(f.readline().rstrip())"
      ],
      "metadata": {
        "id": "9hw3JE69YuOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 26\n",
        "import os\n",
        "from openmm.app import (\n",
        "    PDBFile, Modeller, ForceField,\n",
        "    DCDReporter, StateDataReporter,\n",
        "    Simulation, HBonds, NoCutoff\n",
        ")\n",
        "from openmm import LangevinIntegrator, unit\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "classical_dir = os.path.join(out_root, 'classical')\n",
        "os.makedirs(classical_dir, exist_ok=True)\n",
        "\n",
        "pdb      = PDBFile(os.path.join(out_root, 'full.pdb'))\n",
        "ff_impl  = ForceField('amber99sbildn.xml', 'amber99_obc.xml')\n",
        "modeller = Modeller(pdb.topology, pdb.positions)\n",
        "modeller.addHydrogens(ff_impl)\n",
        "\n",
        "system = ff_impl.createSystem(\n",
        "    modeller.topology,\n",
        "    nonbondedMethod=NoCutoff,\n",
        "    constraints=HBonds\n",
        ")\n",
        "integrator = LangevinIntegrator(\n",
        "    300 * unit.kelvin,\n",
        "    1.0 / unit.picosecond,\n",
        "    2.0 * unit.femtoseconds\n",
        ")\n",
        "sim = Simulation(modeller.topology, system, integrator)\n",
        "sim.context.setPositions(modeller.positions)\n",
        "sim.minimizeEnergy()\n",
        "sim.context.setVelocitiesToTemperature(300*unit.kelvin)\n",
        "\n",
        "dcd_path = os.path.join(classical_dir, 'classical.dcd')\n",
        "log_path = os.path.join(classical_dir, 'classical.log')\n",
        "sim.reporters.append(DCDReporter(dcd_path, 50))\n",
        "sim.reporters.append(StateDataReporter(\n",
        "    log_path, 1000, step=True, time=True,\n",
        "    potentialEnergy=True, temperature=True\n",
        "))\n",
        "\n",
        "nsteps = int(80_000.0 / 0.002)\n",
        "print(f\"Running classic MD for {nsteps:,} steps (~80 ns)…\")\n",
        "sim.step(nsteps)\n",
        "print(\"Classical MD complete\")\n",
        "print(\"Trajectory: \", dcd_path)\n",
        "print(\"Log: \", log_path)\n",
        "print(f\"Wall time: {(time.time() - t0)/3600:.2f} hours\")"
      ],
      "metadata": {
        "id": "O1-vuje3Ymgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Cell (Classical)\n",
        "import mdtraj as md\n",
        "import os\n",
        "\n",
        "root       = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "classical_dir = os.path.join(root, 'classical')\n",
        "\n",
        "dcd_path      = os.path.join(classical_dir, 'classical.dcd')\n",
        "log_path      = os.path.join(classical_dir, 'classical.log')\n",
        "topology_path = os.path.join(root,       'full.pdb')\n",
        "\n",
        "print(\"DCD exists?   \", os.path.exists(dcd_path), dcd_path)\n",
        "print(\"LOG exists?   \", os.path.exists(log_path), log_path)\n",
        "print(\"PDB exists?   \", os.path.exists(topology_path), topology_path)\n",
        "\n",
        "traj = md.load_dcd(dcd_path, top=topology_path)\n",
        "print(f\"✔ Loaded classical trajectory: {traj.n_frames} frames × {traj.n_atoms} atoms\")\n",
        "\n",
        "print(\"\\nFirst 10 lines of classical.log:\")\n",
        "with open(log_path, 'r') as f:\n",
        "    for _ in range(10):\n",
        "        print(f.readline().rstrip())"
      ],
      "metadata": {
        "id": "vB9UNEOTYZ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 27\n",
        "import glob, os\n",
        "import numpy as np\n",
        "import mdtraj as md\n",
        "from scipy.ndimage import gaussian_filter, minimum_filter\n",
        "from scipy.cluster.hierarchy import fclusterdata\n",
        "from skimage.segmentation import watershed\n",
        "from openmm.unit import MOLAR_GAS_CONSTANT_R, kelvin, kilojoule_per_mole\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as pe\n",
        "\n",
        "root      = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "traj_pdb  = os.path.join(root, 'full.pdb')\n",
        "classical = sorted(glob.glob(os.path.join(root, 'classical', 'run*', 'classical.dcd')))\n",
        "\n",
        "phi_all, psi_all = [], []\n",
        "for dcd in classical:\n",
        "    traj = md.load(dcd, top=traj_pdb, stride=10)\n",
        "    top  = traj.topology\n",
        "    phi_idx = [\n",
        "        top.select('resname ACE and name C')[0],\n",
        "        top.select('resname ALA and name N')[0],\n",
        "        top.select('resname ALA and name CA')[0],\n",
        "        top.select('resname ALA and name C')[0]\n",
        "    ]\n",
        "    psi_idx = [\n",
        "        top.select('resname ALA and name N')[0],\n",
        "        top.select('resname ALA and name CA')[0],\n",
        "        top.select('resname ALA and name C')[0],\n",
        "        top.select('resname NME and name N')[0]\n",
        "    ]\n",
        "    phi = np.degrees(md.compute_dihedrals(traj, [phi_idx])[:,0])\n",
        "    psi = np.degrees(md.compute_dihedrals(traj, [psi_idx])[:,0])\n",
        "    phi_all.append(phi)\n",
        "    psi_all.append(psi)\n",
        "\n",
        "phi = np.concatenate(phi_all)\n",
        "psi = np.concatenate(psi_all)\n",
        "\n",
        "nbins   = 180\n",
        "edges   = np.linspace(-180.0, 180.0, nbins+1)\n",
        "hist, _, _ = np.histogram2d(phi, psi, bins=[edges, edges], density=False)\n",
        "P       = hist / hist.sum()\n",
        "kT      = (MOLAR_GAS_CONSTANT_R * 300 * kelvin).value_in_unit(kilojoule_per_mole)\n",
        "with np.errstate(divide='ignore'):\n",
        "    F = -kT * np.log(P)\n",
        "F = np.nan_to_num(F, nan=F[np.isfinite(F)].max()+1.0)\n",
        "\n",
        "F_blur = gaussian_filter(F, sigma=2)\n",
        "\n",
        "Fmin     = F_blur.min()\n",
        "ΔG_cut   = 3.5\n",
        "basin_mask = (F_blur <= Fmin + ΔG_cut)\n",
        "\n",
        "local_min = (F_blur == minimum_filter(F_blur, size=3))\n",
        "min_coords = np.argwhere(local_min & (F_blur <= Fmin + ΔG_cut))\n",
        "\n",
        "bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
        "coords_deg  = np.array([[bin_centers[i], bin_centers[j]] for i,j in min_coords])\n",
        "\n",
        "if len(coords_deg) > 1:\n",
        "    labels = fclusterdata(coords_deg, t=20.0, criterion='distance')\n",
        "else:\n",
        "    labels = np.ones(len(coords_deg), dtype=int)\n",
        "unique_labels = np.unique(labels)\n",
        "\n",
        "markers = np.zeros_like(F_blur, dtype=int)\n",
        "for (i,j), lab in zip(min_coords, labels):\n",
        "    markers[i,j] = lab\n",
        "\n",
        "basin_labels = watershed(\n",
        "    F_blur,\n",
        "    markers=markers,\n",
        "    mask=basin_mask,\n",
        "    connectivity=1\n",
        ")\n",
        "\n",
        "basin_masks = {int(lab): (basin_labels == lab) for lab in unique_labels}\n",
        "print(f\"Strictly identified {len(unique_labels)} basins (from 3×80 ns):\")\n",
        "for lab in unique_labels:\n",
        "    pts   = coords_deg[labels == lab]\n",
        "    center = pts.mean(axis=0)\n",
        "    print(f\"  Basin {lab}: φ₀ ≈ {center[0]:.1f}°, ψ₀ ≈ {center[1]:.1f}°\")\n",
        "\n",
        "\n",
        "Fmin     = F_blur.min()\n",
        "basin_mask = (F_blur <= Fmin + ΔG_cut)\n",
        "\n",
        "basin_labels = watershed(\n",
        "    F_blur,\n",
        "    markers=markers,\n",
        "    mask=basin_mask,\n",
        "    connectivity=1\n",
        ")\n",
        "H, _, _ = np.histogram2d(phi, psi,\n",
        "                        bins=[edges, edges],\n",
        "                        density=True)\n",
        "with np.errstate(divide='ignore'):\n",
        "    F2 = -kT * np.log(H)\n",
        "F2_masked = np.ma.masked_where(H == 0, F2)\n",
        "\n",
        "xc = 0.5*(edges[:-1] + edges[1:])\n",
        "yc = xc\n",
        "Xc, Yc = np.meshgrid(xc, yc)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,5))\n",
        "cf = ax.contourf(\n",
        "    Xc, Yc, F2_masked.T,\n",
        "    levels=50,\n",
        "    cmap='viridis'\n",
        ")\n",
        "\n",
        "for lab in unique_labels:\n",
        "    mask_lab = (basin_labels == lab).astype(int)\n",
        "    ax.contour(\n",
        "        Xc, Yc, mask_lab.T,\n",
        "        levels=[0.5],\n",
        "        colors='white',\n",
        "        linewidths=2\n",
        "    )\n",
        "for lab in unique_labels:\n",
        "    phi0, psi0 = coords_deg[labels==lab].mean(axis=0)\n",
        "    ax.text(phi0, psi0, f'Basin {lab}',\n",
        "            color='white', fontsize=12, fontweight='bold',\n",
        "            ha='center', va='center',\n",
        "            path_effects=[pe.withStroke(linewidth=3, foreground='black')])\n",
        "\n",
        "ax.set_aspect('equal')\n",
        "ax.set_xlim(-180, 180)\n",
        "ax.set_ylim(-180, 180)\n",
        "ax.set_xlabel(r'$\\phi$ (°)')\n",
        "ax.set_ylabel(r'$\\psi$ (°)')\n",
        "ax.set_title('Classical FES with Basin Outlines')\n",
        "\n",
        "cbar = fig.colorbar(cf, ax=ax, pad=0.02)\n",
        "cbar.set_label('Free Energy (kJ/mol)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9KdsdNNBTizZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 28\n",
        "\n",
        "import os, glob, shutil\n",
        "import numpy as np\n",
        "import mdtraj as md\n",
        "\n",
        "root      = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "traj_pdb  = os.path.join(root, 'full.pdb')\n",
        "cache_dir = os.path.join(root, 'phi_psi_cache')\n",
        "\n",
        "if os.path.exists(cache_dir):\n",
        "    shutil.rmtree(cache_dir)\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "classical      = sorted(glob.glob(os.path.join(root, 'classical', 'run*', 'classical.dcd')))\n",
        "force_bias     = sorted(glob.glob(os.path.join(root, 'output', 'hybrid_force_biasing', 'run*', 'hybrid.dcd')))\n",
        "all_dcds       = classical + force_bias\n",
        "\n",
        "def cache_phi_psi(dcd, stride=10):\n",
        "    protocol = os.path.basename(os.path.dirname(os.path.dirname(dcd)))\n",
        "    replica  = os.path.basename(os.path.dirname(dcd))\n",
        "    base     = f\"{protocol}_{replica}_{os.path.basename(dcd).replace('.dcd','')}\"\n",
        "    phi_file = os.path.join(cache_dir, f\"{base}_phi.npy\")\n",
        "    psi_file = os.path.join(cache_dir, f\"{base}_psi.npy\")\n",
        "    if os.path.exists(phi_file) and os.path.exists(psi_file):\n",
        "        return\n",
        "\n",
        "    traj = md.load(dcd, top=traj_pdb, stride=stride)\n",
        "    top  = traj.topology\n",
        "\n",
        "    phi_idx = [\n",
        "        top.select('resname ACE and name C')[0],\n",
        "        top.select('resname ALA and name N')[0],\n",
        "        top.select('resname ALA and name CA')[0],\n",
        "        top.select('resname ALA and name C')[0]\n",
        "    ]\n",
        "    psi_idx = [\n",
        "        top.select('resname ALA and name N')[0],\n",
        "        top.select('resname ALA and name CA')[0],\n",
        "        top.select('resname ALA and name C')[0],\n",
        "        top.select('resname NME and name N')[0]\n",
        "    ]\n",
        "    φ = np.degrees(md.compute_dihedrals(traj, [phi_idx])[:,0])\n",
        "    ψ = np.degrees(md.compute_dihedrals(traj, [psi_idx])[:,0])\n",
        "\n",
        "    np.save(phi_file, φ)\n",
        "    np.save(psi_file, ψ)\n",
        "    print(f\"Cached φ/ψ → {base}\")\n",
        "\n",
        "def cache_omega(dcd, stride=10):\n",
        "    protocol = os.path.basename(os.path.dirname(os.path.dirname(dcd)))\n",
        "    replica  = os.path.basename(os.path.dirname(dcd))\n",
        "    base     = f\"{protocol}_{replica}_omega\"\n",
        "    out_fn   = os.path.join(cache_dir, f\"{base}.npy\")\n",
        "    if os.path.exists(out_fn):\n",
        "        return\n",
        "\n",
        "    traj = md.load(dcd, top=traj_pdb, stride=stride)\n",
        "    top  = traj.topology\n",
        "\n",
        "    omega_idx = [\n",
        "        top.select('resname ALA and name CA')[0],\n",
        "        top.select('resname ALA and name C' )[0],\n",
        "        top.select('resname NME and name N')[0],\n",
        "        top.select('resname NME and name C')[0]\n",
        "    ]\n",
        "    ω = np.degrees(md.compute_dihedrals(traj, [omega_idx])[:,0])\n",
        "\n",
        "    np.save(out_fn, ω)\n",
        "    print(f\"Cached ω     → {base}\")\n",
        "\n",
        "for dcd in all_dcds:\n",
        "    cache_phi_psi(dcd)\n",
        "    cache_omega(dcd)\n",
        "\n",
        "print(\"All dihedral caches written to:\", cache_dir)"
      ],
      "metadata": {
        "id": "nwn3eC4eUyji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 29\n",
        "import glob\n",
        "import numpy as np\n",
        "import mdtraj as md\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "root     = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "traj_pdb = f'{root}/full.pdb'\n",
        "classical_paths  = sorted(glob.glob(f'{root}/classical/run*/classical.dcd'))\n",
        "force_bias_paths = sorted(glob.glob(f'{root}/output/hybrid_force_biasing/run*/hybrid.dcd'))\n",
        "\n",
        "traj_dict = {\n",
        "    'classical': classical_paths,\n",
        "    'hybrid': force_bias_paths\n",
        "}\n",
        "\n",
        "rows = []\n",
        "\n",
        "top0 = md.load(classical_paths[0], top=traj_pdb).topology\n",
        "omega_idx = [\n",
        "    top0.select('resname ALA and name CA')[0],\n",
        "    top0.select('resname ALA and name C') [0],\n",
        "    top0.select('resname NME and name N')[0],\n",
        "    top0.select('resname NME and name C')[0]\n",
        "]\n",
        "\n",
        "nbins     = len(edges)-1\n",
        "bin_width = 360.0/nbins\n",
        "\n",
        "for method, paths in traj_dict.items():\n",
        "    counts = {lab: 0 for lab in unique_labels}\n",
        "    cis = trans = total = 0\n",
        "\n",
        "    for p in paths:\n",
        "        traj  = md.load(p, top=traj_pdb, stride=10)\n",
        "        phi   = np.degrees(md.compute_dihedrals(traj, [phi_idx])[:,0])\n",
        "        psi   = np.degrees(md.compute_dihedrals(traj, [psi_idx])[:,0])\n",
        "        omega = np.degrees(md.compute_dihedrals(traj, [omega_idx])[:,0])\n",
        "\n",
        "        total += len(phi)\n",
        "        i_phi = np.clip(((phi + 180)//bin_width).astype(int), 0, nbins-1)\n",
        "        i_psi = np.clip(((psi + 180)//bin_width).astype(int), 0, nbins-1)\n",
        "\n",
        "        labs = basin_labels[i_phi, i_psi]\n",
        "        for lab in labs:\n",
        "            if lab in counts:\n",
        "                counts[lab] += 1\n",
        "\n",
        "        cis   += np.sum(np.abs(omega) <  30.0)\n",
        "        trans += np.sum(np.abs(omega) >= 30.0)\n",
        "\n",
        "    P_ref = max(counts.values())/total\n",
        "    P     = {lab: counts[lab]/total for lab in counts}\n",
        "    dG    = {lab: -kT * np.log(P[lab]/P_ref) for lab in P}\n",
        "\n",
        "    P_cis = cis/(cis+trans)\n",
        "    dG_ct = -kT * np.log(P_cis/(1.0 - P_cis)) if cis and trans else np.nan\n",
        "\n",
        "    row = {'method': method}\n",
        "    row.update({f'P_basin{lab}': P[lab]    for lab in P})\n",
        "    row.update({f'dG_basin{lab}': dG[lab]  for lab in dG})\n",
        "    row['P_cis']        = P_cis\n",
        "    row['dG_cis_trans'] = dG_ct\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows).set_index('method')\n",
        "print(df)\n",
        "\n",
        "pop_cols = sorted([c for c in df.columns if c.startswith('P_basin')])\n",
        "dg_cols  = sorted([c for c in df.columns if c.startswith('dG_basin')])\n",
        "\n",
        "methods  = df.index.tolist()\n",
        "n_basins = len(pop_cols)\n",
        "x        = np.arange(n_basins)\n",
        "width    = 0.35\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
        "\n",
        "for i, method in enumerate(methods):\n",
        "    pops = df.loc[method, pop_cols].values\n",
        "    ax1.bar(x + (i - 0.5)*width, pops, width,\n",
        "            label=method.replace('_',' ').title(),\n",
        "            capsize=4)\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels([f'Basin {c[-1]}' for c in pop_cols])\n",
        "ax1.set_ylabel('Population')\n",
        "ax1.set_title('Basin Populations')\n",
        "ax1.legend()\n",
        "\n",
        "for i, method in enumerate(methods):\n",
        "    dgs = df.loc[method, dg_cols].values\n",
        "    ax2.bar(x + (i - 0.5)*width, dgs, width,\n",
        "            label=method.replace('_',' ').title(),\n",
        "            capsize=4)\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels([f'Basin {c[-1]}' for c in dg_cols])\n",
        "ax2.set_ylabel('ΔG (kJ/mol)')\n",
        "ax2.set_title('Relative Free Energies')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TbznNX8gUB6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 30\n",
        "\n",
        "import os, glob\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "root      = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "dt_ps     = 0.1\n",
        "nbins     = 180\n",
        "cache_dir = f'{root}/phi_psi_cache'\n",
        "\n",
        "paths = {\n",
        "    'classical':            sorted(glob.glob(f'{root}/classical/run*/classical.dcd')),\n",
        "    'hybrid': sorted(glob.glob(f'{root}/output/hybrid_force_biasing/run*/hybrid.dcd')),\n",
        "}\n",
        "\n",
        "def get_phi_psi(dcd):\n",
        "    protocol = os.path.basename(os.path.dirname(os.path.dirname(dcd)))\n",
        "    run_id   = os.path.basename(os.path.dirname(dcd))\n",
        "    base     = os.path.basename(dcd).replace('.dcd','')\n",
        "    phi = np.load(os.path.join(cache_dir, f\"{protocol}_{run_id}_{base}_phi.npy\"))\n",
        "    psi = np.load(os.path.join(cache_dir, f\"{protocol}_{run_id}_{base}_psi.npy\"))\n",
        "    return phi, psi\n",
        "\n",
        "def compute_mfpt(labels, A, B):\n",
        "    idx = np.where(labels==A)[0]\n",
        "    times = []\n",
        "    for i in idx:\n",
        "        sub = labels[i+1:]\n",
        "        f = np.where(sub==B)[0]\n",
        "        if f.size:\n",
        "            times.append(f[0]+1)\n",
        "    return np.nan if not times else np.mean(times)*dt_ps/1000\n",
        "\n",
        "data = {m: [] for m in paths}\n",
        "for method, dcds in paths.items():\n",
        "    for dcd in dcds:\n",
        "        phi, psi = get_phi_psi(dcd)\n",
        "        bw = 360/nbins\n",
        "        i_phi = np.clip(((phi+180)//bw).astype(int), 0, nbins-1)\n",
        "        i_psi = np.clip(((psi+180)//bw).astype(int), 0, nbins-1)\n",
        "        labels = basin_labels[i_phi, i_psi]\n",
        "\n",
        "        rec = {}\n",
        "        for A in unique_labels:\n",
        "            for B in unique_labels:\n",
        "                if A==B: continue\n",
        "                m = compute_mfpt(labels, A, B)\n",
        "                rec[f'MFPT_{A}→{B}'] = m\n",
        "                rec[f'k_{A}→{B}'] = np.nan if np.isnan(m) else 1/m\n",
        "        data[method].append(rec)\n",
        "\n",
        "def bootstrap_ci(arr, n=10000):\n",
        "    arr = np.array(arr)\n",
        "    boots = [np.nanmean(np.random.choice(arr, len(arr), replace=True)) for _ in range(n)]\n",
        "    return np.nanpercentile(boots, [2.5,97.5])\n",
        "\n",
        "summary = {}\n",
        "for method, recs in data.items():\n",
        "    dfm = pd.DataFrame(recs)\n",
        "    stats = {}\n",
        "    for col in dfm:\n",
        "        vals = dfm[col].dropna().values\n",
        "        mean = np.nanmean(vals)\n",
        "        lo, hi = bootstrap_ci(vals) if len(vals)>1 else (np.nan,np.nan)\n",
        "        stats[col] = {'mean': mean, 'lo': lo, 'hi': hi}\n",
        "    summary[method] = pd.DataFrame(stats).T\n",
        "\n",
        "out = pd.concat(summary, axis=1)\n",
        "print(out)\n",
        "\n",
        "mfpt_keys = [k for k in out.index if k.startswith('MFPT')]\n",
        "methods   = list(paths.keys())\n",
        "width     = 0.8 / len(methods)\n",
        "x1        = np.arange(len(mfpt_keys))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,4))\n",
        "for i, method in enumerate(methods):\n",
        "    means = out[(method,'mean')].loc[mfpt_keys]\n",
        "    err_lo = means - out[(method,'lo')].loc[mfpt_keys]\n",
        "    err_hi = out[(method,'hi')].loc[mfpt_keys] - means\n",
        "    ax.bar(x1 + (i - (len(methods)-1)/2)*width, means, width,\n",
        "           yerr=[err_lo, err_hi], label=method.replace('_',' ').title())\n",
        "ax.set_xticks(x1)\n",
        "ax.set_xticklabels(mfpt_keys, rotation=45, ha='right')\n",
        "ax.set_ylabel('MFPT (ns)')\n",
        "ax.set_title('MFPT ±95% CI')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "rate_keys = [k for k in out.index if k.startswith('k_')]\n",
        "x2        = np.arange(len(rate_keys))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,4))\n",
        "for i, method in enumerate(methods):\n",
        "    means = out[(method,'mean')].loc[rate_keys]\n",
        "    err_lo = means - out[(method,'lo')].loc[rate_keys]\n",
        "    err_hi = out[(method,'hi')].loc[rate_keys] - means\n",
        "    ax.bar(x2 + (i - (len(methods)-1)/2)*width, means, width,\n",
        "           yerr=[err_lo, err_hi], label=method.replace('_',' ').title())\n",
        "ax.set_xticks(x2)\n",
        "ax.set_xticklabels(rate_keys, rotation=45, ha='right')\n",
        "ax.set_ylabel('Rate (1/ns)')\n",
        "ax.set_title('Transition Rates ±95% CI')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_qh5pLSBWBtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 31\n",
        "\n",
        "import os, glob, numpy as np, matplotlib.pyplot as plt\n",
        "from numpy.linalg import eigvals\n",
        "\n",
        "root      = '/content/drive/MyDrive/final_folder'\n",
        "cache_dir = os.path.join(root, 'phi_psi_cache')\n",
        "\n",
        "def discrete_traj(dcd):\n",
        "    proto   = os.path.basename(os.path.dirname(os.path.dirname(dcd)))\n",
        "    run_id  = os.path.basename(os.path.dirname(dcd))\n",
        "    feat    = os.path.basename(dcd).replace('.dcd','')\n",
        "    base    = f\"{proto}_{run_id}_{feat}\"\n",
        "    phi     = np.load(os.path.join(cache_dir, f\"{base}_phi.npy\"))\n",
        "    psi     = np.load(os.path.join(cache_dir, f\"{base}_psi.npy\"))\n",
        "    nb      = basin_labels.shape[0]\n",
        "    bw      = 360.0/nb\n",
        "    i       = np.clip(((phi + 180.0)//bw).astype(int), 0, nb-1)\n",
        "    j       = np.clip(((psi + 180.0)//bw).astype(int), 0, nb-1)\n",
        "    return (basin_labels[i, j] - 1).astype(int)\n",
        "\n",
        "cls_paths = sorted(glob.glob(f'{root}/classical/run*/classical.dcd'))\n",
        "hyb_paths = sorted(glob.glob(f'{root}/output/hybrid_force_biasing/run*/hybrid.dcd'))\n",
        "\n",
        "d_cls = [discrete_traj(p) for p in cls_paths]\n",
        "d_hyb = [discrete_traj(p) for p in hyb_paths]\n",
        "\n",
        "n_states  = int(basin_labels.max())\n",
        "lags      = [1, 10, 20]\n",
        "dt_ns     = 0.1 / 1000.0\n",
        "\n",
        "def count_matrix(dtrajs, lag):\n",
        "    C = np.zeros((n_states, n_states), dtype=int)\n",
        "    for traj in dtrajs:\n",
        "        for t in range(len(traj) - lag):\n",
        "            C[traj[t], traj[t+lag]] += 1\n",
        "    return C\n",
        "\n",
        "its = {}\n",
        "for label, data in [('Classical', d_cls), ('Hybrid', d_hyb)]:\n",
        "    τ1 = []\n",
        "    for lag in lags:\n",
        "        C    = count_matrix(data, lag).astype(float)\n",
        "        rows = C.sum(axis=1, keepdims=True)\n",
        "        T    = np.where(rows > 0, C/rows, 0.0)\n",
        "        λ1   = np.sort(np.real(eigvals(T)))[-2]\n",
        "        τ1.append(-(lag*dt_ns)/np.log(λ1))\n",
        "    its[label] = τ1\n",
        "\n",
        "print(\"\\nMode-1 implied timescales (ns):\")\n",
        "for lbl, t in its.items():\n",
        "    print(f\"  {lbl}: {[f'{x:.4f}' for x in t]}\")\n",
        "\n",
        "lag0 = 10\n",
        "C0   = count_matrix(d_cls, lag0).astype(float)\n",
        "rows = C0.sum(axis=1, keepdims=True)\n",
        "T0   = np.where(rows > 0, C0/rows, 0.0)\n",
        "\n",
        "print(\"\\nCK test errors (classical, τ₀ = 1 ps):\")\n",
        "for m in [1, 2, 5]:\n",
        "    Emp   = count_matrix(d_cls, lag0*m).astype(float)\n",
        "    rows  = Emp.sum(axis=1, keepdims=True)\n",
        "    Emp   = np.where(rows > 0, Emp/rows, 0.0)\n",
        "    Pred  = np.linalg.matrix_power(T0, m)\n",
        "    L1    = np.abs(Emp-Pred).sum()\n",
        "    maxel = np.abs(Emp-Pred).max()\n",
        "    print(f\"  m={m}:  L₁ = {L1:.4f}   max|ΔP| = {maxel:.4f}\")\n",
        "\n",
        "lags_ns = np.array(lags) * dt_ns\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11,4.5))\n",
        "\n",
        "for lbl, t in its.items():\n",
        "    ax1.plot(lags_ns, t, marker='o', label=lbl)\n",
        "ax1.set(xlabel='Lag τ (ns)', ylabel='ITS τ₁ (ns)',\n",
        "        title='Mode-1 Implied Timescales')\n",
        "ax1.legend(); ax1.grid(True)\n",
        "\n",
        "m    = 5\n",
        "Emp5 = count_matrix(d_cls, lag0*m).astype(float)\n",
        "Emp5 = np.where(Emp5.sum(axis=1,keepdims=True)>0,\n",
        "                Emp5/Emp5.sum(axis=1,keepdims=True), 0.0)\n",
        "im = ax2.imshow(Emp5, vmin=0, vmax=1, cmap='viridis')\n",
        "ax2.set(title=f'Classical CK (m={m}, τ₀=1 ps)',\n",
        "        xlabel='to state', ylabel='from state')\n",
        "fig.colorbar(im, ax=ax2, shrink=0.8)\n",
        "\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "7J1jtSjdWe38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 32\n",
        "\n",
        "import os, glob, sys, subprocess, importlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _ensure(pkgs):\n",
        "    for p in pkgs:\n",
        "        try: importlib.import_module(p)\n",
        "        except ImportError: subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p, \"-q\"])\n",
        "_ensure([\"numpy\",\"matplotlib\",\"mdtraj\",\"pymbar\",\"scikit-learn\",\"scipy\"])\n",
        "\n",
        "import mdtraj as md\n",
        "from pymbar import timeseries\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from scipy.stats import norm\n",
        "\n",
        "ROOT      = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "TOPO      = os.path.join(ROOT, 'full.pdb')\n",
        "CACHE_DIR = os.path.join(ROOT, 'phi_psi_cache')\n",
        "\n",
        "CL_GLOB = os.path.join(ROOT, 'classical', 'run*', 'classical.dcd')\n",
        "FB_GLOB = os.path.join(ROOT, 'output', 'hybrid_force_biasing', 'run*', 'hybrid.dcd')\n",
        "\n",
        "STRIDE    = 10\n",
        "DT_PS     = 0.1\n",
        "DT_EFF_PS = STRIDE * DT_PS\n",
        "\n",
        "SIM_H = {'classical': 1.40, 'hybrid': 1.41}\n",
        "HYBRID_OVERHEAD_H = (2.0/60.0) + 0.07 + (1.0/60.0)\n",
        "HOURS = {\n",
        "    'classical': SIM_H['classical'],\n",
        "    'hybrid_force_biasing': SIM_H['hybrid_force_biasing'] + HYBRID_OVERHEAD_H\n",
        "}\n",
        "\n",
        "BOOTSTRAP_B = 2000\n",
        "RNG = np.random.default_rng(0)\n",
        "\n",
        "def dihedral_idx_phi(top):\n",
        "    return [\n",
        "        top.select('resname ACE and name C')[0],\n",
        "        top.select('resname ALA and name N')[0],\n",
        "        top.select('resname ALA and name CA')[0],\n",
        "        top.select('resname ALA and name C')[0],\n",
        "    ]\n",
        "\n",
        "def load_phi_from_cache_or_dcd(protocol, dcd_path):\n",
        "    \"\"\"Try cache first; fall back to computing from DCD.\"\"\"\n",
        "    run_id  = os.path.basename(os.path.dirname(dcd_path))\n",
        "    base    = os.path.basename(dcd_path).replace('.dcd','')\n",
        "    phi_fn  = os.path.join(CACHE_DIR, f\"{protocol}_{run_id}_{base}_phi.npy\")\n",
        "    if os.path.exists(phi_fn):\n",
        "        return np.load(phi_fn)\n",
        "\n",
        "    t = md.load(dcd_path, top=TOPO, stride=STRIDE)\n",
        "    idx = dihedral_idx_phi(t.topology)\n",
        "    return np.degrees(md.compute_dihedrals(t, [idx])[:,0])\n",
        "\n",
        "def circ_ess_count(phi_deg):\n",
        "    x = np.deg2rad(np.asarray(phi_deg, float))\n",
        "    s, c = np.sin(x), np.cos(x)\n",
        "    def safe_g(a):\n",
        "        if a.size < 10 or np.nanvar(a) < 1e-12: return np.nan\n",
        "        try:\n",
        "            g = timeseries.statistical_inefficiency(a)\n",
        "            return g if (np.isfinite(g) and g>0) else np.nan\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "    g = np.nanmax([safe_g(s), safe_g(c)])\n",
        "    if not np.isfinite(g): return np.nan\n",
        "    return len(x)/g\n",
        "\n",
        "def ess_per_gpu_hour(protocol, dcds):\n",
        "    vals = []\n",
        "    for dcd in dcds:\n",
        "        phi = load_phi_from_cache_or_dcd(protocol, dcd)\n",
        "        ESS = circ_ess_count(phi)\n",
        "        h   = HOURS.get(protocol, np.nan)\n",
        "        vals.append(ESS / h if (np.isfinite(ESS) and np.isfinite(h) and h>0) else np.nan)\n",
        "    return np.array(vals, float)\n",
        "\n",
        "cl_dcds = sorted(glob.glob(CL_GLOB))\n",
        "fb_dcds = sorted(glob.glob(FB_GLOB))\n",
        "if not cl_dcds: raise SystemExit(\"No classical DCDs found.\")\n",
        "if not fb_dcds: print(\"No Hybrid FB DCDs found under 'output/...'; violin will still show the axis.\")\n",
        "\n",
        "cl_vals_all = ess_per_gpu_hour('classical', cl_dcds)\n",
        "fb_vals_all = ess_per_gpu_hour('hybrid_force_biasing', fb_dcds)\n",
        "\n",
        "x_cl = cl_vals_all[np.isfinite(cl_vals_all) & (cl_vals_all > 0)]\n",
        "if x_cl.size < 3:\n",
        "    raise SystemExit(\"Need ≥3 classical runs with finite positive ESSφ/GPU-hour for a stable GMM.\")\n",
        "\n",
        "logx = np.log10(x_cl).reshape(-1,1)\n",
        "g1 = GaussianMixture(1, covariance_type='full', random_state=0).fit(logx)\n",
        "g2 = GaussianMixture(2, covariance_type='full', random_state=0).fit(logx)\n",
        "bic1, bic2 = g1.bic(logx), g2.bic(logx)\n",
        "dBIC = bic2 - bic1\n",
        "\n",
        "w = g2.weights_; m = g2.means_.ravel(); s = np.sqrt(g2.covariances_.ravel())\n",
        "ordr = np.argsort(m); w, m, s = w[ordr], m[ordr], s[ordr]\n",
        "A = 1/(2*s[1]**2) - 1/(2*s[0]**2)\n",
        "B = m[0]/(s[0]**2) - m[1]/(s[1]**2)\n",
        "C = (m[1]**2)/(2*s[1]**2) - (m[0]**2)/(2*s[0]**2) + np.log((w[1]*s[0])/(w[0]*s[1]))\n",
        "thr_log  = (-B + np.sign(B)*np.sqrt(max(0.0, B*B - 4*A*C)))/(2*A) if abs(A)>1e-12 else -C/B\n",
        "ESS_thr_h = 10**thr_log\n",
        "\n",
        "wins_2, thr_boot = 0, []\n",
        "for _ in range(BOOTSTRAP_B):\n",
        "    s_ = RNG.choice(x_cl, size=len(x_cl), replace=True)\n",
        "    s_ = s_[(s_>0) & np.isfinite(s_)]\n",
        "    if s_.size < 3: continue\n",
        "    lx = np.log10(s_).reshape(-1,1)\n",
        "    g1b = GaussianMixture(1, covariance_type='full', random_state=0).fit(lx)\n",
        "    g2b = GaussianMixture(2, covariance_type='full', random_state=0).fit(lx)\n",
        "    dB  = g2b.bic(lx) - g1b.bic(lx)\n",
        "    if dB < -10: wins_2 += 1\n",
        "    wb = g2b.weights_; mb = g2b.means_.ravel(); sb = np.sqrt(g2b.covariances_.ravel())\n",
        "    o  = np.argsort(mb); wb, mb, sb = wb[o], mb[o], sb[o]\n",
        "    A  = 1/(2*sb[1]**2) - 1/(2*sb[0]**2)\n",
        "    B  = mb[0]/(sb[0]**2) - mb[1]/(sb[1]**2)\n",
        "    C  = (mb[1]**2)/(2*sb[1]**2) - (mb[0]**2)/(2*sb[0]**2) + np.log((wb[1]*sb[0])/(wb[0]*sb[1]))\n",
        "    thr_b = (-B + np.sign(B)*np.sqrt(max(0.0, B*B - 4*A*C)))/(2*A) if abs(A)>1e-12 else -C/B\n",
        "    thr_boot.append(10**thr_b)\n",
        "\n",
        "thr_boot = np.array(thr_boot, float)\n",
        "support_pct = 100.0 * wins_2 / max(1, len(thr_boot))\n",
        "thr_ci = np.percentile(thr_boot, [2.5, 50, 97.5]) if thr_boot.size else [np.nan]*3\n",
        "\n",
        "n_cl = np.isfinite(cl_vals_all).sum()\n",
        "n_fb = np.isfinite(fb_vals_all).sum()\n",
        "print(\"\\n=== Classical ESSφ per GPU-hour bimodality ===\")\n",
        "print(f\"ΔBIC (2 − 1) on log10(ESSφ/GPU-h): {dBIC:.2f}  (negative favors two components)\")\n",
        "print(f\"Mode-separating threshold (ESSφ/GPU-h): {ESS_thr_h:.3g}\")\n",
        "print(f\"Bootstrap support for two modes (ΔBIC < −10): {support_pct:.1f}%  (N={len(thr_boot)})\")\n",
        "print(f\"Threshold stability (ESSφ/GPU-h): median {thr_ci[1]:.3g}, 95% CI [{thr_ci[0]:.3g}, {thr_ci[2]:.3g}]\")\n",
        "print(f\"Included runs → Classical: {n_cl}, Hybrid FB: {n_fb}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(11, 3.6))\n",
        "\n",
        "log_vals = np.log10(x_cl)\n",
        "axes[0].hist(log_vals, bins=10, density=True, alpha=0.6)\n",
        "xs = np.linspace(log_vals.min()-0.2, log_vals.max()+0.2, 400)\n",
        "pdf_mix = (w[0]*norm.pdf(xs, m[0], s[0]) + w[1]*norm.pdf(xs, m[1], s[1]))\n",
        "axes[0].plot(xs, pdf_mix, lw=2)\n",
        "axes[0].axvline(thr_log, ls='--', lw=1)\n",
        "axes[0].set_xlabel('log10(ESSφ / GPU-hour)')\n",
        "axes[0].set_ylabel('density')\n",
        "axes[0].set_title('Classical: 2-GMM fit & mode split (ESS/GPU-h)')\n",
        "\n",
        "cl_plot = cl_vals_all[np.isfinite(cl_vals_all) & (cl_vals_all > 0)]\n",
        "fb_plot = fb_vals_all[np.isfinite(fb_vals_all) & (fb_vals_all > 0)]\n",
        "data    = [cl_plot, fb_plot]\n",
        "labels  = ['Classical', 'Hybrid FB']\n",
        "\n",
        "plot_data = [d if d.size else np.array([np.nan]) for d in data]\n",
        "parts = axes[1].violinplot(plot_data, showmeans=True, showextrema=False)\n",
        "for b in parts['bodies']:\n",
        "    b.set_alpha(0.4)\n",
        "\n",
        "for i, vals in enumerate(data, start=1):\n",
        "    v = vals[np.isfinite(vals)]\n",
        "    if v.size:\n",
        "        x = np.random.normal(loc=i, scale=0.05, size=v.size)\n",
        "        axes[1].scatter(x, v, s=18, alpha=0.85)\n",
        "\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].set_xticks([1,2]); axes[1].set_xticklabels(labels)\n",
        "axes[1].axhline(ESS_thr_h, ls='--', lw=1)\n",
        "axes[1].set_ylabel('ESSφ per GPU-hour (log scale)')\n",
        "axes[1].set_title('Per-run ESSφ/GPU-h with classical threshold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n[Export] ESS_thr_h = {ESS_thr_h:.6g}  (use for FAST/SLOW by ESS/GPU-h)\")"
      ],
      "metadata": {
        "id": "uA_MPaVbXUIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 33\n",
        "\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "root = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "\n",
        "acceptance = {}\n",
        "for prot in ['hybrid_force_biasing']:\n",
        "    acc_paths = sorted(glob.glob(os.path.join(root, 'output', prot, 'run*', 'accepted.npy')))\n",
        "    rates = [np.load(f).mean() for f in acc_paths]\n",
        "    n = len(rates)\n",
        "    if n > 1:\n",
        "        mean_rate = np.mean(rates)\n",
        "        from scipy.stats import t\n",
        "        se = np.std(rates, ddof=1) / np.sqrt(n)\n",
        "        t_mult = t.ppf(0.975, df=n-1)\n",
        "        delta = t_mult * se\n",
        "    else:\n",
        "        mean_rate = rates[0] if n==1 else np.nan\n",
        "        delta = np.nan\n",
        "\n",
        "    acceptance[prot] = {\n",
        "        'paths':  acc_paths,\n",
        "        'rates':  rates,\n",
        "        'mean':   mean_rate,\n",
        "        'delta':  delta\n",
        "    }\n",
        "\n",
        "for prot, info in acceptance.items():\n",
        "    print(f\"Protocol: {prot}\")\n",
        "    print(\"  Files:      \", info['paths'])\n",
        "    print(\"  Rates:      \", np.round(info['rates'], 3))\n",
        "    mean  = info['mean']\n",
        "    delta = info['delta']\n",
        "    print(f\"  Mean ±95% CI: {mean:.3f} ± {delta:.3f}\")"
      ],
      "metadata": {
        "id": "X6AZ_JavXvv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 34\n",
        "\n",
        "import os, glob, math, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pymbar import timeseries\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "root       = '/content/drive/MyDrive/alanine_dipeptide'\n",
        "cache_dir  = os.path.join(root, 'phi_psi_cache')\n",
        "\n",
        "if 'STRIDE' not in globals():  STRIDE = 10\n",
        "if 'DT_PS' not in globals():   DT_PS  = 0.1\n",
        "\n",
        "DT_EFF_PS  = STRIDE * DT_PS\n",
        "DT_EFF_NS  = DT_EFF_PS / 1000.0\n",
        "\n",
        "if 'HOURS' not in globals():\n",
        "    SIM_H = {'classical': 1.40, 'hybrid_force_biasing': 1.41}\n",
        "    HYBRID_OVERHEAD_H = (2.0/60.0) + 0.07 + (1.0/60.0)\n",
        "    HOURS = {\n",
        "        'classical': SIM_H['classical'],\n",
        "        'hybrid_force_biasing': SIM_H['hybrid_force_biasing'] + HYBRID_OVERHEAD_H,\n",
        "    }\n",
        "ALLOWED_PROTOCOLS = set(HOURS.keys())\n",
        "\n",
        "if 'ESS_thr_h' not in globals():\n",
        "    raise RuntimeError(\"ESS_thr_h not found. Run the bimodality cell (classical-only GMM on log10(ESSφ/GPU-hour)) first.\")\n",
        "\n",
        "def circ_ess_per_ns(angle_deg):\n",
        "    \"\"\"Return (ESS per ns, tau_int in ps) via max{g[sin], g[cos]} for a circular variable.\"\"\"\n",
        "    x = np.deg2rad(np.asarray(angle_deg, float))\n",
        "    s, c = np.sin(x), np.cos(x)\n",
        "    def _g(a):\n",
        "        if a.size < 10 or np.nanvar(a) < 1e-16:\n",
        "            return np.nan\n",
        "        try:\n",
        "            g = timeseries.statistical_inefficiency(a)\n",
        "            return g if (np.isfinite(g) and g > 0) else np.nan\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "    g = np.nanmax([_g(s), _g(c)])\n",
        "    if not np.isfinite(g):\n",
        "        return np.nan, np.nan\n",
        "    ESS_total = len(x) / g\n",
        "    traj_ns   = len(x) * DT_EFF_NS\n",
        "    return (ESS_total / traj_ns) if traj_ns > 0 else np.nan, (g * DT_EFF_PS)\n",
        "\n",
        "def bootstrap_ci_mean(vals, nboot=10000, seed=7):\n",
        "    v = np.asarray(vals, float); v = v[np.isfinite(v)]\n",
        "    if v.size < 2:\n",
        "        m = float(v.mean()) if v.size == 1 else np.nan\n",
        "        return m, np.nan, np.nan\n",
        "    rng = np.random.default_rng(seed)\n",
        "    bs = rng.choice(v, size=(nboot, v.size), replace=True).mean(axis=1)\n",
        "    return float(v.mean()), float(np.percentile(bs, 2.5)), float(np.percentile(bs, 97.5))\n",
        "\n",
        "def perm_test_diff_means(a, b, nperm=20000, seed=7):\n",
        "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
        "    a = a[np.isfinite(a)]; b = b[np.isfinite(b)]\n",
        "    if a.size == 0 or b.size == 0:\n",
        "        return np.nan\n",
        "    obs = np.nanmean(a) - np.nanmean(b)\n",
        "    comb = np.concatenate([a, b])\n",
        "    rng = np.random.default_rng(seed)\n",
        "    cnt = 0\n",
        "    for _ in range(nperm):\n",
        "        rng.shuffle(comb)\n",
        "        aa = comb[:len(a)]; bb = comb[len(a):]\n",
        "        cnt += (abs(aa.mean() - bb.mean()) >= abs(obs))\n",
        "    return (cnt + 1) / (nperm + 1)\n",
        "\n",
        "phi_files = sorted(glob.glob(os.path.join(cache_dir, '*_phi.npy')))\n",
        "records = []\n",
        "\n",
        "for fphi in phi_files:\n",
        "    base = os.path.basename(fphi)[:-8]\n",
        "    parts = base.rsplit('_', 2)\n",
        "    if len(parts) != 3:\n",
        "        continue\n",
        "    protocol, run_id, feat = parts\n",
        "    if protocol not in ALLOWED_PROTOCOLS:\n",
        "        continue\n",
        "\n",
        "    fpsi = os.path.join(cache_dir, f\"{base}_psi.npy\")\n",
        "    if not os.path.exists(fpsi):\n",
        "        continue\n",
        "\n",
        "    phi = np.load(fphi)\n",
        "    psi = np.load(fpsi)\n",
        "\n",
        "    ess_phi_ns, _ = circ_ess_per_ns(phi)\n",
        "    ess_psi_ns, _ = circ_ess_per_ns(psi)\n",
        "\n",
        "    traj_ns = len(phi) * DT_EFF_NS\n",
        "    ess_phi_per_h = (ess_phi_ns * traj_ns) / HOURS[protocol] if np.isfinite(ess_phi_ns) else np.nan\n",
        "    ess_psi_per_h = (ess_psi_ns * traj_ns) / HOURS[protocol] if np.isfinite(ess_psi_ns) else np.nan\n",
        "\n",
        "    records.append({\n",
        "        'protocol': protocol,\n",
        "        'run_id': run_id,\n",
        "        'ESS_phi_per_h':  ess_phi_per_h,\n",
        "        'ESS_psi_per_h':  ess_psi_per_h\n",
        "    })\n",
        "\n",
        "if not records:\n",
        "    raise RuntimeError(\"No valid φ/ψ cache pairs found for allowed protocols. Check cache_dir naming.\")\n",
        "\n",
        "df = pd.DataFrame.from_records(records).sort_values(['protocol','run_id']).reset_index(drop=True)\n",
        "\n",
        "df['mode_phi'] = np.where(df['ESS_phi_per_h'] >= ESS_thr_h, 'FAST', 'SLOW')\n",
        "\n",
        "def group_stats(metric):\n",
        "    A = df.loc[df['mode_phi']=='FAST', metric].values\n",
        "    B = df.loc[df['mode_phi']=='SLOW', metric].values\n",
        "    mA, loA, hiA = bootstrap_ci_mean(A)\n",
        "    mB, loB, hiB = bootstrap_ci_mean(B)\n",
        "    ratio = np.nan if not (np.isfinite(mA) and np.isfinite(mB) and mB>0) else mA/mB\n",
        "    p = perm_test_diff_means(A, B)\n",
        "    return {'A_mean':mA,'A_lo':loA,'A_hi':hiA,'NA':np.sum(np.isfinite(A)),\n",
        "            'B_mean':mB,'B_lo':loB,'B_hi':hiB,'NB':np.sum(np.isfinite(B)),\n",
        "            'ratio':ratio,'p_perm':p}\n",
        "\n",
        "S_phi_h = group_stats('ESS_phi_per_h')\n",
        "S_psi_h = group_stats('ESS_psi_per_h')\n",
        "\n",
        "def fmt(s):\n",
        "    return (f\"FAST mean={s['A_mean']:.3g} 95%CI[{s['A_lo']:.3g},{s['A_hi']:.3g}] (N={s['NA']}); \"\n",
        "            f\"SLOW mean={s['B_mean']:.3g} 95%CI[{s['B_lo']:.3g},{s['B_hi']:.3g}] (N={s['NB']}); \"\n",
        "            f\"FAST/SLOW={s['ratio']:.3g}; perm p={s['p_perm']:.3g}\")\n",
        "\n",
        "print(\"\\n=== FAST vs SLOW (by classical φ threshold on ESS/GPU-hour) — GPU-hour metrics ===\")\n",
        "print(\"φ ESS per GPU-hour: \", fmt(S_phi_h))\n",
        "print(\"ψ ESS per GPU-hour: \", fmt(S_psi_h))\n",
        "\n",
        "def plot_bar(metric, title, ylabel):\n",
        "    groups = ['FAST','SLOW']\n",
        "    means = [np.nanmean(df.loc[df['mode_phi']==g, metric].values) for g in groups]\n",
        "    lois, his = [], []\n",
        "    for g in groups:\n",
        "        vals = df.loc[df['mode_phi']==g, metric].values\n",
        "        m, lo, hi = bootstrap_ci_mean(vals, nboot=5000, seed=7)\n",
        "        lois.append(m - lo); his.append(hi - m)\n",
        "    xpos = np.arange(len(groups))\n",
        "    plt.figure(figsize=(4,3))\n",
        "    plt.bar(xpos, means, yerr=[lois, his], capsize=4)\n",
        "    plt.xticks(xpos, groups); plt.ylabel(ylabel); plt.title(title)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "plot_bar('ESS_phi_per_h', 'φ: ESS per GPU-hour (FAST vs SLOW)', 'ESSφ / GPU-hour')\n",
        "plot_bar('ESS_psi_per_h', 'ψ: ESS per GPU-hour (FAST vs SLOW)', 'ESSψ / GPU-hour')"
      ],
      "metadata": {
        "id": "9IBdcTq7YPjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 35\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if 'edge_index' in globals() and isinstance(edge_index, torch.Tensor):\n",
        "    N_nodes = int(edge_index.max().item()) + 1\n",
        "else:\n",
        "    N_nodes = 3\n",
        "\n",
        "T0 = globals().get('T0', 150)\n",
        "\n",
        "batch_vec = torch.zeros(N_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "t_node = torch.full((N_nodes,), int(T0), dtype=torch.long, device=device)\n",
        "\n",
        "if 'edge_index' in globals() and isinstance(edge_index, torch.Tensor):\n",
        "    edge_index = edge_index.to(device=device, dtype=torch.long)\n",
        "\n",
        "print(f\"Synthesized batch_vec ({batch_vec.shape}), t_node ({t_node.shape}), T0={T0}, N_nodes={N_nodes}\")"
      ],
      "metadata": {
        "id": "YI2XzF8h8X2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, torch, glob, os, re, matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, wilcoxon\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if 'edge_index' in globals() and isinstance(edge_index, torch.Tensor):\n",
        "    N_nodes = int(edge_index.max().item()) + 1\n",
        "else:\n",
        "    N_nodes = 3\n",
        "\n",
        "T0 = globals().get('T0', 150)\n",
        "batch_vec = torch.zeros(N_nodes, dtype=torch.long, device=device)\n",
        "t_node    = torch.full((N_nodes,), int(T0), dtype=torch.long, device=device)\n",
        "if 'edge_index' in globals() and isinstance(edge_index, torch.Tensor):\n",
        "    edge_index = edge_index.to(device=device, dtype=torch.long)\n",
        "\n",
        "print(f\"Synthesized batch_vec ({batch_vec.shape}), t_node ({t_node.shape}), T0={T0}, N_nodes={N_nodes}\")\n",
        "\n",
        "def wrap(a): return (a + np.pi) % (2*np.pi) - np.pi\n",
        "def ang_to_feat(a): return np.stack([np.sin(a), np.cos(a)], axis=-1)\n",
        "def feat_to_ang(feat): return np.arctan2(feat[...,0], feat[...,1])\n",
        "\n",
        "def propose_from_torsions(theta_np):\n",
        "    \"\"\"theta_np: (3,) [phi, psi, omega] radians -> returns wrapped (3,) new angles\"\"\"\n",
        "    theta_np = np.asarray(theta_np).reshape(-1)\n",
        "    if theta_np.shape[0] < 3:\n",
        "        theta_np = np.concatenate([theta_np, [np.pi]])\n",
        "    x_feats = ang_to_feat(theta_np)\n",
        "    if N_nodes == 2:\n",
        "        x_feats = x_feats[:2]\n",
        "    x_t = torch.as_tensor(x_feats, dtype=torch.float32, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            y = mh_jump(x_t)\n",
        "        except TypeError:\n",
        "            y = mh_jump(x_t, edge_index, batch_vec, t_node)\n",
        "\n",
        "    if isinstance(y, (list, tuple)):\n",
        "        y = y[0]\n",
        "    if isinstance(y, torch.Tensor):\n",
        "        y = y.detach().cpu().numpy()\n",
        "    y = np.asarray(y)\n",
        "\n",
        "    if y.ndim == 2 and y.shape[1] == 2:\n",
        "        ang_out = feat_to_ang(y)\n",
        "    elif y.ndim == 1 and y.shape[0] == (2 if N_nodes==2 else 3):\n",
        "        ang_out = y\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unexpected mh_jump output shape {y.shape}\")\n",
        "    if N_nodes == 2:\n",
        "        ang_out = np.concatenate([ang_out, [theta_np[2]]])\n",
        "    return wrap(ang_out)\n",
        "\n",
        "def bootstrap_ci(vals, iters=5000, alpha=0.05, rng=np.random.default_rng(0)):\n",
        "    vals = np.asarray(vals)\n",
        "    n = len(vals)\n",
        "    idxs = rng.integers(0, n, size=(iters, n))\n",
        "    means = vals[idxs].mean(axis=1)\n",
        "    lo, hi = np.percentile(means, [100*alpha/2, 100*(1-alpha/2)])\n",
        "    return float(lo), float(hi)\n",
        "\n",
        "assert 'torsions' in globals(), \"Expected 'torsions' array in scope (T x 2/3). Load caches before running.\"\n",
        "if torsions.shape[1] == 2:\n",
        "    torsions = np.concatenate([torsions, np.full((len(torsions),1), np.pi)], axis=1)\n",
        "\n",
        "N = min(1000, len(torsions))\n",
        "rng = np.random.default_rng(42)\n",
        "idxs = rng.choice(len(torsions), size=N, replace=False)\n",
        "\n",
        "disp_phi, disp_psi = [], []\n",
        "first_exc = None\n",
        "for i in idxs:\n",
        "    x = torsions[i]\n",
        "    try:\n",
        "        x_prop = propose_from_torsions(x)\n",
        "        d = wrap(x_prop - x)\n",
        "        if np.all(np.isfinite(d)):\n",
        "            disp_phi.append(d[0]); disp_psi.append(d[1])\n",
        "    except Exception as e:\n",
        "        if first_exc is None:\n",
        "            first_exc = e\n",
        "\n",
        "successes = len(disp_phi)\n",
        "print(f\"\\nSuccessful proposals: {successes} / {N}\")\n",
        "if successes == 0:\n",
        "    raise RuntimeError(f\"No proposals succeeded. First exception:\\n{repr(first_exc)}\")\n",
        "\n",
        "disp_phi = np.array(disp_phi); disp_psi = np.array(disp_psi)\n",
        "\n",
        "def summarize(label, arr):\n",
        "    m = float(arr.mean())\n",
        "    lo, hi = bootstrap_ci(arr, iters=3000)\n",
        "    sk = float(skew(arr))\n",
        "    nz = arr[np.abs(arr) > 1e-12]\n",
        "    p = float(wilcoxon(nz).pvalue) if len(nz) >= 10 else float(\"nan\")\n",
        "    print(f\"{label}: mean={m:+.4f} rad  (95% CI [{lo:+.4f}, {hi:+.4f}]),  skew={sk:+.3f},  sign-test p={p:.3f}\")\n",
        "    return m, (lo, hi), sk, p\n",
        "\n",
        "print(\"\\n=== Displacement symmetry (ϕ/ψ) @ N=1000 ===\")\n",
        "m_phi, ci_phi, sk_phi, p_phi = summarize(\"phi\", disp_phi)\n",
        "m_psi, ci_psi, sk_psi, p_psi = summarize(\"psi\", disp_psi)\n",
        "\n",
        "bins = 40\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4), dpi=200)\n",
        "\n",
        "ax = axes[0]\n",
        "ax.hist(disp_phi, bins=bins, density=True, color=\"C0\", edgecolor=\"black\", linewidth=0.6)\n",
        "ax.axvline(0.0, linestyle='--', color=\"black\", linewidth=2)\n",
        "ax.axvline(disp_phi.mean(), linestyle='-', color=\"red\", linewidth=2)\n",
        "ax.set_title(r\"$\\Delta \\phi$ distribution\", fontsize=16)\n",
        "ax.set_xlabel(\"radians\", fontsize=14)\n",
        "ax.set_ylabel(\"density\", fontsize=14)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "\n",
        "ax = axes[1]\n",
        "ax.hist(disp_psi, bins=bins, density=True, color=\"C0\", edgecolor=\"black\", linewidth=0.6)\n",
        "ax.axvline(0.0, linestyle='--', color=\"black\", linewidth=2)\n",
        "ax.axvline(disp_psi.mean(), linestyle='-', color=\"red\", linewidth=2)\n",
        "ax.set_title(r\"$\\Delta \\psi$ distribution\", fontsize=16)\n",
        "ax.set_xlabel(\"radians\", fontsize=14)\n",
        "ax.set_ylabel(\"density\", fontsize=14)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wm4qCKcs8dwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 37\n",
        "from scipy.stats import fisher_exact\n",
        "table = [[7,2], [1,6]]\n",
        "OR, p = fisher_exact(table, alternative='two-sided')\n",
        "print(OR, p)"
      ],
      "metadata": {
        "id": "xwDHvnC38z15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}